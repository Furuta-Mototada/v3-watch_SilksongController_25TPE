{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f6287b",
   "metadata": {},
   "source": [
    "# WhisperX Batch Processing for Silksong Sessions\n",
    "\n",
    "**üéØ Purpose:** Process multiple audio sessions with WhisperX for word-level transcription\n",
    "\n",
    "**üìä Status:** Your test run was successful! Results:\n",
    "- ‚úÖ 26 segments transcribed\n",
    "- ‚úÖ 734 words with timestamps\n",
    "- ‚úÖ 18.3% gesture keyword coverage\n",
    "- ‚úÖ High confidence scores (0.8+ average)\n",
    "\n",
    "**‚ö° Performance:** ~2-3 minutes per 10-minute audio file on Tesla T4\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Setup\n",
    "\n",
    "1. **Upload all your session folders** to Google Drive:\n",
    "   ```\n",
    "   My Drive/silksong_data/\n",
    "   ‚îú‚îÄ‚îÄ 20251017_125600_session/audio_16k.wav\n",
    "   ‚îú‚îÄ‚îÄ 20251017_130000_session/audio_16k.wav\n",
    "   ‚îú‚îÄ‚îÄ 20251017_131500_session/audio_16k.wav\n",
    "   ‚îî‚îÄ‚îÄ [more sessions]/audio_16k.wav\n",
    "   ```\n",
    "\n",
    "2. **Update the session list** in the batch processing cell below\n",
    "\n",
    "3. **Run all cells** and let it process overnight\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e19fbe",
   "metadata": {},
   "source": [
    "# WhisperX Transcription for Silksong Gesture Controller\n",
    "\n",
    "**Project:** Hollow Knight: Silksong Gesture Recognition\n",
    "\n",
    "**Purpose:** Transcribe audio recordings with word-level timestamps using WhisperX large-v3\n",
    "\n",
    "**Hardware:** GPU-accelerated (CUDA)\n",
    "\n",
    "---\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Enable GPU:** Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "2. **Upload audio files** to Google Drive: `My Drive/silksong_data/[session_name]/audio_16k.wav`\n",
    "3. **Run all cells** in order\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8085f87",
   "metadata": {},
   "source": [
    "## 1. Verify GPU Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d52c1",
   "metadata": {},
   "source": [
    "## 2. Install WhisperX and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install WhisperX\n",
    "!pip install -q git+https://github.com/m-bain/whisperx.git\n",
    "\n",
    "# Install PyTorch with CUDA support\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645625e",
   "metadata": {},
   "source": [
    "## 3. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6903e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify mount\n",
    "import os\n",
    "base_path = '/content/drive/My Drive/silksong_data'\n",
    "\n",
    "if os.path.exists(base_path):\n",
    "    print(f\"‚úÖ Google Drive mounted successfully!\")\n",
    "    print(f\"\\nAvailable sessions:\")\n",
    "    sessions = [d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))]\n",
    "    for session in sessions:\n",
    "        print(f\"  - {session}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Path not found: {base_path}\")\n",
    "    print(f\"   Please create the folder structure in Google Drive first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5be433",
   "metadata": {},
   "source": [
    "## 4. Define Custom Prompt for Gesture Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec94c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom prompt optimized for Silksong gesture recognition\n",
    "CUSTOM_PROMPT = (\n",
    "    \"The following is a transcription of a person playing the video game \"\n",
    "    \"Hollow Knight: Silksong. They are speaking their character's actions out loud. \"\n",
    "    \"The key commands are: jump, punch, attack, turn, walk, walking, walk start, \"\n",
    "    \"idle, rest, stop, noise. The speaker might say phrases like 'I'm gonna jump here', \"\n",
    "    \"'punch punch', 'let me walk over there', 'okay, now idle', or 'that was noise'.\"\n",
    ")\n",
    "\n",
    "print(\"Custom prompt configured:\")\n",
    "print(f\"  {CUSTOM_PROMPT[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a3157",
   "metadata": {},
   "source": [
    "## 5. Single Session Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f54de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURE THIS: Set your session name\n",
    "SESSION_NAME = \"20251017_125600_session\"  # Change this to your session\n",
    "\n",
    "# Paths\n",
    "audio_path = f\"/content/drive/My Drive/silksong_data/{SESSION_NAME}/audio_16k.wav\"\n",
    "output_dir = f\"/content/drive/My Drive/silksong_data/{SESSION_NAME}/\"\n",
    "\n",
    "# Verify audio file exists\n",
    "if not os.path.exists(audio_path):\n",
    "    print(f\"‚ùå ERROR: Audio file not found: {audio_path}\")\n",
    "    print(f\"   Please upload audio_16k.wav to this location in Google Drive.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Audio file found: {audio_path}\")\n",
    "\n",
    "    # Get file size\n",
    "    size_mb = os.path.getsize(audio_path) / (1024 * 1024)\n",
    "    print(f\"   Size: {size_mb:.2f} MB\")\n",
    "\n",
    "    # Get duration (approximate)\n",
    "    import librosa\n",
    "    duration = librosa.get_duration(path=audio_path)\n",
    "    print(f\"   Duration: {duration/60:.2f} minutes\")\n",
    "    print(f\"   Estimated transcription time: {duration/60 * 0.5:.1f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464edb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run WhisperX transcription\n",
    "import whisperx\n",
    "import torch\n",
    "\n",
    "print(\"üöÄ Starting WhisperX transcription...\\n\")\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "compute_type = \"float16\" if device == \"cuda\" else \"float32\"\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Compute type: {compute_type}\\n\")\n",
    "\n",
    "# Load model\n",
    "print(\"Loading WhisperX model (large-v3)...\")\n",
    "model = whisperx.load_model(\n",
    "    \"large-v3\",\n",
    "    device=device,\n",
    "    compute_type=compute_type,\n",
    "    language=\"en\"\n",
    ")\n",
    "print(\"‚úÖ Model loaded\\n\")\n",
    "\n",
    "# Load audio\n",
    "print(\"Loading audio...\")\n",
    "audio = whisperx.load_audio(audio_path)\n",
    "print(\"‚úÖ Audio loaded\\n\")\n",
    "\n",
    "# Transcribe with custom prompt\n",
    "print(\"Transcribing with custom gesture prompt...\")\n",
    "result = model.transcribe(\n",
    "    audio,\n",
    "    batch_size=16,\n",
    "    initial_prompt=CUSTOM_PROMPT\n",
    ")\n",
    "print(f\"‚úÖ Transcription complete!\")\n",
    "print(f\"   Segments: {len(result['segments'])}\")\n",
    "print(f\"   Language: {result.get('language', 'unknown')}\\n\")\n",
    "\n",
    "# Apply forced alignment for word-level timestamps\n",
    "print(\"Applying forced alignment for word-level timestamps...\")\n",
    "model_a, metadata = whisperx.load_align_model(\n",
    "    language_code=\"en\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "result = whisperx.align(\n",
    "    result[\"segments\"],\n",
    "    model_a,\n",
    "    metadata,\n",
    "    audio,\n",
    "    device,\n",
    "    return_char_alignments=False\n",
    ")\n",
    "\n",
    "# Count words\n",
    "word_count = sum(len(seg.get('words', [])) for seg in result.get('segments', []))\n",
    "print(f\"‚úÖ Alignment complete!\")\n",
    "print(f\"   Words with timestamps: {word_count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import json\n",
    "\n",
    "output_json = os.path.join(output_dir, \"whisperx_output.json\")\n",
    "output_txt = os.path.join(output_dir, \"whisperx_output_summary.txt\")\n",
    "\n",
    "# Save JSON\n",
    "with open(output_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "print(f\"‚úÖ Saved JSON: {output_json}\")\n",
    "\n",
    "# Save summary\n",
    "with open(output_txt, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"WhisperX Transcription Summary\\n\")\n",
    "    f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "    f.write(f\"Session: {SESSION_NAME}\\n\")\n",
    "    f.write(f\"Segments: {len(result.get('segments', []))}\\n\")\n",
    "    f.write(f\"Words: {word_count}\\n\\n\")\n",
    "\n",
    "    # First 50 words\n",
    "    f.write(\"First 50 words with timestamps:\\n\")\n",
    "    f.write(\"-\" * 70 + \"\\n\")\n",
    "\n",
    "    all_words = []\n",
    "    for seg in result.get('segments', []):\n",
    "        all_words.extend(seg.get('words', []))\n",
    "\n",
    "    for i, word_info in enumerate(all_words[:50], 1):\n",
    "        word = word_info.get('word', '')\n",
    "        start = word_info.get('start', 0)\n",
    "        end = word_info.get('end', 0)\n",
    "        score = word_info.get('score', 0)\n",
    "        f.write(f\"{i:3d}. {start:7.2f}s-{end:7.2f}s | {word:20s} | conf: {score:.3f}\\n\")\n",
    "\n",
    "print(f\"‚úÖ Saved summary: {output_txt}\")\n",
    "print(f\"\\nüéâ Transcription complete! Results saved to Google Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da5871a",
   "metadata": {},
   "source": [
    "## 6. Preview Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few segments\n",
    "print(\"First 5 segments with word-level timestamps:\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, segment in enumerate(result['segments'][:5], 1):\n",
    "    print(f\"\\n[Segment {i}] {segment['start']:.2f}s - {segment['end']:.2f}s\")\n",
    "    print(f\"Text: {segment['text']}\")\n",
    "\n",
    "    if 'words' in segment:\n",
    "        print(\"Words:\")\n",
    "        for word_info in segment['words']:\n",
    "            word = word_info['word']\n",
    "            start = word_info['start']\n",
    "            end = word_info['end']\n",
    "            conf = word_info.get('score', 0)\n",
    "            print(f\"  {start:6.2f}s-{end:6.2f}s: '{word}' (conf: {conf:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Total segments: {len(result['segments'])}\")\n",
    "print(f\"Total words: {word_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e08867",
   "metadata": {},
   "source": [
    "## 7. Gesture Keyword Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536be9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count gesture keywords in transcription\n",
    "from collections import Counter\n",
    "\n",
    "gesture_keywords = ['jump', 'punch', 'attack', 'turn', 'walk', 'walking', 'idle', 'rest', 'stop', 'noise']\n",
    "\n",
    "# Extract all words\n",
    "all_words = []\n",
    "for seg in result['segments']:\n",
    "    for word_info in seg.get('words', []):\n",
    "        all_words.append(word_info['word'].lower().strip())\n",
    "\n",
    "# Count gesture keywords\n",
    "gesture_counts = Counter()\n",
    "for word in all_words:\n",
    "    if word in gesture_keywords:\n",
    "        gesture_counts[word] += 1\n",
    "\n",
    "# Display results\n",
    "print(\"Gesture Keyword Frequency Analysis\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nTotal words transcribed: {len(all_words)}\")\n",
    "print(f\"Gesture keywords found: {sum(gesture_counts.values())}\")\n",
    "print(f\"Coverage: {sum(gesture_counts.values()) / len(all_words) * 100:.1f}%\\n\")\n",
    "\n",
    "print(\"Gesture breakdown:\")\n",
    "for keyword in sorted(gesture_keywords):\n",
    "    count = gesture_counts.get(keyword, 0)\n",
    "    if count > 0:\n",
    "        bar = '‚ñà' * int(count / 2)\n",
    "        print(f\"  {keyword:10s}: {count:3d} {bar}\")\n",
    "    else:\n",
    "        print(f\"  {keyword:10s}: {count:3d}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a2c28d",
   "metadata": {},
   "source": [
    "## 8. Batch Processing (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b11082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ CONFIGURE THIS: Add ALL your session folder names here\n",
    "SESSIONS_TO_PROCESS = [\n",
    "    \"20251017_125600_session\",\n",
    "    \"20251017_130000_session\",\n",
    "    \"20251017_131500_session\",\n",
    "    \"20251017_132000_session\",\n",
    "    \"20251017_133000_session\",\n",
    "    # Add all your actual session folder names here\n",
    "    # Check your Google Drive: My Drive/silksong_data/ for the exact names\n",
    "]\n",
    "\n",
    "# üìÅ Auto-discover sessions (uncomment to use this instead)\n",
    "# import os\n",
    "# base_path = \"/content/drive/My Drive/silksong_data/\"\n",
    "# SESSIONS_TO_PROCESS = [d for d in os.listdir(base_path)\n",
    "#                       if os.path.isdir(os.path.join(base_path, d))\n",
    "#                       and os.path.exists(os.path.join(base_path, d, \"audio_16k.wav\"))]\n",
    "\n",
    "base_path = \"/content/drive/My Drive/silksong_data/\"\n",
    "\n",
    "print(\"üöÄ BATCH PROCESSING SILKSONG SESSIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# üîç Pre-flight check: Verify which sessions exist\n",
    "existing_sessions = []\n",
    "missing_sessions = []\n",
    "total_duration = 0\n",
    "\n",
    "print(\"üìã Session inventory:\")\n",
    "for session in SESSIONS_TO_PROCESS:\n",
    "    audio_path = os.path.join(base_path, session, \"audio_16k.wav\")\n",
    "    if os.path.exists(audio_path):\n",
    "        existing_sessions.append(session)\n",
    "        # Get file info\n",
    "        size_mb = os.path.getsize(audio_path) / (1024 * 1024)\n",
    "        duration = librosa.get_duration(path=audio_path)\n",
    "        total_duration += duration\n",
    "        print(f\"   ‚úÖ {session:25s} | {size_mb:5.1f}MB | {duration/60:5.1f}min\")\n",
    "    else:\n",
    "        missing_sessions.append(session)\n",
    "        print(f\"   ‚ùå {session:25s} | FILE NOT FOUND\")\n",
    "\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"   ‚úÖ Found: {len(existing_sessions)} sessions ({total_duration/60:.1f} minutes total)\")\n",
    "print(f\"   ‚ùå Missing: {len(missing_sessions)} sessions\")\n",
    "print(f\"   ‚è±Ô∏è  Estimated processing time: {total_duration/60 * 0.3:.1f} minutes\")\n",
    "\n",
    "if missing_sessions:\n",
    "    print(f\"\\n‚ö†Ô∏è  Missing audio files - please upload to Google Drive:\")\n",
    "    for session in missing_sessions:\n",
    "        print(f\"      üìÅ My Drive/silksong_data/{session}/audio_16k.wav\")\n",
    "    print(f\"\\n   üí° Tip: You can continue with the {len(existing_sessions)} found sessions\")\n",
    "\n",
    "if len(existing_sessions) == 0:\n",
    "    print(f\"\\nüö® No sessions found! Please check your Google Drive folder structure.\")\n",
    "    print(f\"   Expected: My Drive/silksong_data/[session_name]/audio_16k.wav\")\n",
    "else:\n",
    "    print(f\"\\nüéØ Ready to process {len(existing_sessions)} sessions!\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# üöÄ START BATCH PROCESSING\n",
    "if len(existing_sessions) > 0:\n",
    "    print(f\"\\nüöÄ STARTING BATCH TRANSCRIPTION...\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    successful_sessions = []\n",
    "    failed_sessions = []\n",
    "\n",
    "    for i, session in enumerate(existing_sessions, 1):\n",
    "        print(f\"\\nüìç [{i:2d}/{len(existing_sessions)}] Processing: {session}\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        audio_path = os.path.join(base_path, session, \"audio_16k.wav\")\n",
    "        output_dir = os.path.join(base_path, session)\n",
    "        output_json = os.path.join(output_dir, \"whisperx_output.json\")\n",
    "\n",
    "        # Check if already processed\n",
    "        if os.path.exists(output_json):\n",
    "            print(f\"   ‚ö° Already processed - skipping (delete {session}/whisperx_output.json to reprocess)\")\n",
    "            successful_sessions.append(session)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # üéµ Load and transcribe\n",
    "            print(f\"   üéµ Loading audio...\")\n",
    "            audio = whisperx.load_audio(audio_path)\n",
    "\n",
    "            print(f\"   ü§ñ Transcribing with large-v3...\")\n",
    "            result = model.transcribe(audio, batch_size=16)\n",
    "\n",
    "            # üéØ Apply alignment\n",
    "            print(f\"   üéØ Applying forced alignment...\")\n",
    "            result = whisperx.align(\n",
    "                result[\"segments\"],\n",
    "                model_a,\n",
    "                metadata,\n",
    "                audio,\n",
    "                device,\n",
    "                return_char_alignments=False\n",
    "            )\n",
    "\n",
    "            # üíæ Save results\n",
    "            print(f\"   üíæ Saving results...\")\n",
    "            with open(output_json, 'w', encoding='utf-8') as f:\n",
    "                json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "            # üìä Summary\n",
    "            word_count = sum(len(seg.get('words', [])) for seg in result.get('segments', []))\n",
    "            segment_count = len(result['segments'])\n",
    "\n",
    "            print(f\"   ‚úÖ SUCCESS: {segment_count} segments, {word_count} words\")\n",
    "            successful_sessions.append(session)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå ERROR: {str(e)}\")\n",
    "            failed_sessions.append((session, str(e)))\n",
    "            continue\n",
    "\n",
    "    # üéâ Final Summary\n",
    "    print(f\"\\n\" + \"=\" * 80)\n",
    "    print(f\"üéâ BATCH PROCESSING COMPLETE!\")\n",
    "    print(f\"=\" * 80)\n",
    "    print(f\"‚úÖ Successful: {len(successful_sessions)} sessions\")\n",
    "    print(f\"‚ùå Failed: {len(failed_sessions)} sessions\")\n",
    "\n",
    "    if successful_sessions:\n",
    "        print(f\"\\n‚úÖ Successfully processed:\")\n",
    "        for session in successful_sessions:\n",
    "            print(f\"   - {session}\")\n",
    "\n",
    "    if failed_sessions:\n",
    "        print(f\"\\n‚ùå Failed sessions:\")\n",
    "        for session, error in failed_sessions:\n",
    "            print(f\"   - {session}: {error}\")\n",
    "\n",
    "    print(f\"\\nüìÅ Results saved to Google Drive: My Drive/silksong_data/[session]/whisperx_output.json\")\n",
    "    print(f\"üí° Next step: Download these files and run label alignment locally\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n‚è∏Ô∏è  Batch processing skipped - no valid sessions found\")\n",
    "    print(f\"   Please upload audio files and try again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7064f0dc",
   "metadata": {},
   "source": [
    "## 9. Download Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ef9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Download ALL processed results\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "print(\"üì• DOWNLOADING ALL TRANSCRIPTION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "base_path = \"/content/drive/My Drive/silksong_data/\"\n",
    "\n",
    "# Find all sessions with whisperx_output.json files\n",
    "processed_sessions = []\n",
    "for item in os.listdir(base_path):\n",
    "    session_path = os.path.join(base_path, item)\n",
    "    json_path = os.path.join(session_path, \"whisperx_output.json\")\n",
    "    if os.path.isdir(session_path) and os.path.exists(json_path):\n",
    "        processed_sessions.append(item)\n",
    "\n",
    "if not processed_sessions:\n",
    "    print(\"‚ùå No processed sessions found!\")\n",
    "    print(\"   Run the batch processing first\")\n",
    "else:\n",
    "    print(f\"üìä Found {len(processed_sessions)} processed sessions:\")\n",
    "    for session in processed_sessions:\n",
    "        print(f\"   ‚úÖ {session}\")\n",
    "\n",
    "    # Option 1: Download individual files\n",
    "    print(f\"\\nüì• Option 1: Download individual files\")\n",
    "    for session in processed_sessions[:3]:  # Limit to first 3 to avoid too many downloads\n",
    "        json_path = os.path.join(base_path, session, \"whisperx_output.json\")\n",
    "        print(f\"   üìÅ Downloading {session}/whisperx_output.json...\")\n",
    "        files.download(json_path)\n",
    "\n",
    "    if len(processed_sessions) > 3:\n",
    "        print(f\"   üí° Only downloaded first 3 files. Uncomment below for more.\")\n",
    "\n",
    "    # Option 2: Create and download ZIP file\n",
    "    print(f\"\\nüì• Option 2: Download as ZIP file\")\n",
    "    zip_path = \"/content/silksong_transcriptions.zip\"\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "        for session in processed_sessions:\n",
    "            json_path = os.path.join(base_path, session, \"whisperx_output.json\")\n",
    "            summary_path = os.path.join(base_path, session, \"whisperx_output_summary.txt\")\n",
    "\n",
    "            # Add JSON file\n",
    "            if os.path.exists(json_path):\n",
    "                zipf.write(json_path, f\"{session}/whisperx_output.json\")\n",
    "\n",
    "            # Add summary if exists\n",
    "            if os.path.exists(summary_path):\n",
    "                zipf.write(summary_path, f\"{session}/whisperx_output_summary.txt\")\n",
    "\n",
    "    print(f\"   üóúÔ∏è  Created ZIP with {len(processed_sessions)} sessions\")\n",
    "    files.download(zip_path)\n",
    "\n",
    "    print(f\"\\n‚úÖ Download complete!\")\n",
    "    print(f\"üìÅ Extract the ZIP file to your local project:\")\n",
    "    print(f\"   data/continuous/[session_name]/whisperx_output.json\")\n",
    "\n",
    "# Uncomment to download ALL individual files:\n",
    "# for session in processed_sessions:\n",
    "#     json_path = os.path.join(base_path, session, \"whisperx_output.json\")\n",
    "#     print(f\"Downloading {session}...\")\n",
    "#     files.download(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe00208",
   "metadata": {},
   "source": [
    "# üìä Batch Analysis & Results\n",
    "\n",
    "## Quick Stats for All Sessions\n",
    "\n",
    "Run this after batch processing to get an overview of all your transcribed sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7672b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Analyze all processed sessions\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "base_path = \"/content/drive/My Drive/silksong_data/\"\n",
    "gesture_keywords = ['jump', 'punch', 'attack', 'turn', 'walk', 'walking', 'idle', 'rest', 'stop', 'noise']\n",
    "\n",
    "print(\"üìä SILKSONG SESSION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find all processed sessions\n",
    "processed_sessions = []\n",
    "for item in os.listdir(base_path):\n",
    "    session_path = os.path.join(base_path, item)\n",
    "    json_path = os.path.join(session_path, \"whisperx_output.json\")\n",
    "    if os.path.isdir(session_path) and os.path.exists(json_path):\n",
    "        processed_sessions.append(item)\n",
    "\n",
    "if not processed_sessions:\n",
    "    print(\"‚ùå No processed sessions found! Run batch processing first.\")\n",
    "else:\n",
    "    # Analyze each session\n",
    "    session_stats = []\n",
    "    total_gestures = Counter()\n",
    "\n",
    "    for session in sorted(processed_sessions):\n",
    "        json_path = os.path.join(base_path, session, \"whisperx_output.json\")\n",
    "\n",
    "        with open(json_path, 'r') as f:\n",
    "            result = json.load(f)\n",
    "\n",
    "        # Count words and gestures\n",
    "        all_words = []\n",
    "        for seg in result['segments']:\n",
    "            for word_info in seg.get('words', []):\n",
    "                all_words.append(word_info['word'].lower().strip())\n",
    "\n",
    "        # Count gesture keywords\n",
    "        gesture_counts = Counter()\n",
    "        for word in all_words:\n",
    "            if word in gesture_keywords:\n",
    "                gesture_counts[word] += 1\n",
    "                total_gestures[word] += 1\n",
    "\n",
    "        # Session stats\n",
    "        stats = {\n",
    "            'session': session,\n",
    "            'segments': len(result['segments']),\n",
    "            'total_words': len(all_words),\n",
    "            'gesture_words': sum(gesture_counts.values()),\n",
    "            'coverage': sum(gesture_counts.values()) / len(all_words) * 100 if all_words else 0\n",
    "        }\n",
    "\n",
    "        # Add individual gesture counts\n",
    "        for gesture in gesture_keywords:\n",
    "            stats[gesture] = gesture_counts.get(gesture, 0)\n",
    "\n",
    "        session_stats.append(stats)\n",
    "\n",
    "    # Create DataFrame for easy viewing\n",
    "    df = pd.DataFrame(session_stats)\n",
    "\n",
    "    print(f\"üìà SUMMARY: {len(processed_sessions)} sessions processed\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Overall stats\n",
    "    total_segments = df['segments'].sum()\n",
    "    total_words = df['total_words'].sum()\n",
    "    total_gesture_words = df['gesture_words'].sum()\n",
    "\n",
    "    print(f\"üéØ Total segments: {total_segments:,}\")\n",
    "    print(f\"üéØ Total words: {total_words:,}\")\n",
    "    print(f\"üéØ Total gesture words: {total_gesture_words:,}\")\n",
    "    print(f\"üéØ Overall gesture coverage: {total_gesture_words/total_words*100:.1f}%\")\n",
    "\n",
    "    print(f\"\\nüìä Per-session breakdown:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{'Session':25s} | {'Segments':8s} | {'Words':6s} | {'Gestures':8s} | {'Coverage':8s}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        print(f\"{row['session']:25s} | {row['segments']:8d} | {row['total_words']:6d} | {row['gesture_words']:8d} | {row['coverage']:7.1f}%\")\n",
    "\n",
    "    print(f\"\\nüéÆ Gesture frequency across all sessions:\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for gesture in sorted(gesture_keywords):\n",
    "        count = total_gestures.get(gesture, 0)\n",
    "        if count > 0:\n",
    "            bar = '‚ñà' * min(count // 5, 50)  # Scale bar\n",
    "            print(f\"  {gesture:10s}: {count:4d} {bar}\")\n",
    "        else:\n",
    "            print(f\"  {gesture:10s}: {count:4d}\")\n",
    "\n",
    "    print(f\"\\nüî• Top sessions by gesture activity:\")\n",
    "    print(\"-\" * 50)\n",
    "    top_sessions = df.nlargest(5, 'gesture_words')[['session', 'gesture_words', 'coverage']]\n",
    "\n",
    "    for _, row in top_sessions.iterrows():\n",
    "        print(f\"  {row['session']:25s}: {row['gesture_words']:3d} gestures ({row['coverage']:.1f}%)\")\n",
    "\n",
    "    print(f\"\\nüí° Next steps:\")\n",
    "    print(f\"   1. Download all JSON files using the cell above\")\n",
    "    print(f\"   2. Move to your local project: data/continuous/[session]/whisperx_output.json\")\n",
    "    print(f\"   3. Run label alignment: python align_voice_labels.py --session [session]\")\n",
    "    print(f\"   4. Train your CNN/LSTM model with the labeled data\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376aa7ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üè† Next Steps: Local Integration\n",
    "\n",
    "After downloading your transcription results:\n",
    "\n",
    "### 1. Move Files to Local Project\n",
    "\n",
    "```bash\n",
    "# Extract downloaded ZIP to your project\n",
    "unzip ~/Downloads/silksong_transcriptions.zip -d /tmp/transcriptions\n",
    "\n",
    "# Move each session's results\n",
    "for session in /tmp/transcriptions/*/; do\n",
    "    session_name=$(basename \"$session\")\n",
    "    cp \"$session/whisperx_output.json\" \\\n",
    "       \"data/continuous/$session_name/whisperx_output.json\"\n",
    "done\n",
    "```\n",
    "\n",
    "### 2. Run Label Alignment\n",
    "\n",
    "```bash\n",
    "# Process each session locally\n",
    "python align_voice_labels.py \\\n",
    "  --session 20251017_125600_session \\\n",
    "  --whisper data/continuous/20251017_125600_session/whisperx_output.json\n",
    "\n",
    "# Or batch process all sessions\n",
    "for session_dir in data/continuous/*/; do\n",
    "    session_name=$(basename \"$session_dir\")\n",
    "    if [ -f \"$session_dir/whisperx_output.json\" ]; then\n",
    "        python align_voice_labels.py \\\n",
    "          --session \"$session_name\" \\\n",
    "          --whisper \"$session_dir/whisperx_output.json\"\n",
    "    fi\n",
    "done\n",
    "```\n",
    "\n",
    "### 3. Continue to Phase IV: Model Training\n",
    "\n",
    "Your gesture data is now ready for CNN/LSTM training! üéâ\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Checklist\n",
    "\n",
    "- [ ] All sessions transcribed with WhisperX\n",
    "- [ ] Results downloaded to local machine  \n",
    "- [ ] Label alignment completed\n",
    "- [ ] Ready for CNN/LSTM training\n",
    "- [ ] Gesture recognition model deployment\n",
    "\n",
    "**You've successfully completed Phase V! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
