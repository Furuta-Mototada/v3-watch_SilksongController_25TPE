{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase V: CNN/LSTM Model Training\n",
        "\n",
        "This notebook trains the CNN/LSTM gesture recognition model using continuous motion data.\n",
        "\n",
        "## Training Pipeline:\n",
        "1. Load continuous sensor recordings\n",
        "2. Load label files\n",
        "3. Create sliding window dataset\n",
        "4. Split train/validation/test sets\n",
        "5. Train model with early stopping\n",
        "6. Evaluate performance\n",
        "7. Save trained model\n",
        "\n",
        "Expected training time: 1-2 hours on CPU, 10-20 minutes on GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "sys.path.append('../src')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Import our model\n",
        "from models.cnn_lstm_model import (\n",
        "    create_cnn_lstm_model,\n",
        "    prepare_data_for_training,\n",
        "    save_model\n",
        ")\n",
        "\n",
        "print(\"\u2713 Imports successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Data\n",
        "\n",
        "Load continuous sensor recordings and their corresponding labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure data paths\n",
        "DATA_DIR = '../data/continuous'\n",
        "SESSION_FILES = [\n",
        "    # Add your session files here\n",
        "    # ('session_01.csv', 'session_01_labels.csv'),\n",
        "    # ('session_02.csv', 'session_02_labels.csv'),\n",
        "]\n",
        "\n",
        "# For demo: use a placeholder\n",
        "if not SESSION_FILES:\n",
        "    print(\"\u26a0\ufe0f  No session files configured.\")\n",
        "    print(\"   Add your continuous recording files to SESSION_FILES list above.\")\n",
        "    print(\"   Example: ('session_01.csv', 'session_01_labels.csv')\")\n",
        "else:\n",
        "    print(f\"Configured {len(SESSION_FILES)} session(s) for training\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and prepare data from all sessions\n",
        "X_all = []\n",
        "y_all = []\n",
        "\n",
        "for sensor_file, labels_file in SESSION_FILES:\n",
        "    print(f\"\\nProcessing {sensor_file}...\")\n",
        "    \n",
        "    # Load files\n",
        "    sensor_path = f\"{DATA_DIR}/{sensor_file}\"\n",
        "    labels_path = f\"{DATA_DIR}/{labels_file}\"\n",
        "    \n",
        "    sensor_data = pd.read_csv(sensor_path)\n",
        "    labels_data = pd.read_csv(labels_path)\n",
        "    \n",
        "    print(f\"  Sensor data: {len(sensor_data)} samples\")\n",
        "    print(f\"  Labels: {len(labels_data)} segments\")\n",
        "    \n",
        "    # Create sliding windows\n",
        "    X, y = prepare_data_for_training(\n",
        "        sensor_data,\n",
        "        labels_data,\n",
        "        window_size=50,  # 1 second at 50Hz\n",
        "        stride=25        # 50% overlap\n",
        "    )\n",
        "    \n",
        "    print(f\"  Generated {len(X)} training windows\")\n",
        "    \n",
        "    X_all.append(X)\n",
        "    y_all.append(y)\n",
        "\n",
        "# Combine all sessions\n",
        "if X_all:\n",
        "    X_combined = np.concatenate(X_all, axis=0)\n",
        "    y_combined = np.concatenate(y_all, axis=0)\n",
        "    \n",
        "    print(f\"\\n\u2713 Total training samples: {len(X_combined)}\")\n",
        "    print(f\"  Input shape: {X_combined.shape}\")\n",
        "    print(f\"  Output shape: {y_combined.shape}\")\n",
        "else:\n",
        "    print(\"\\n\u26a0\ufe0f  No data loaded. Configure SESSION_FILES above.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Data Analysis\n",
        "\n",
        "Analyze class distribution and data quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'y_combined' in locals():\n",
        "    # Gesture names\n",
        "    gesture_names = ['Jump', 'Punch', 'Turn', 'Walk', 'Noise']\n",
        "    \n",
        "    # Count samples per class\n",
        "    class_counts = y_combined.sum(axis=0).astype(int)\n",
        "    \n",
        "    # Display distribution\n",
        "    print(\"Class Distribution:\")\n",
        "    for i, name in enumerate(gesture_names):\n",
        "        count = class_counts[i]\n",
        "        pct = (count / len(y_combined)) * 100\n",
        "        print(f\"  {name:8s}: {count:5d} samples ({pct:5.1f}%)\")\n",
        "    \n",
        "    # Visualize\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(gesture_names, class_counts)\n",
        "    plt.title('Gesture Class Distribution')\n",
        "    plt.ylabel('Number of Samples')\n",
        "    plt.xlabel('Gesture')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Check for imbalance\n",
        "    min_count = class_counts.min()\n",
        "    max_count = class_counts.max()\n",
        "    imbalance_ratio = max_count / min_count\n",
        "    \n",
        "    if imbalance_ratio > 3:\n",
        "        print(f\"\\n\u26a0\ufe0f  Class imbalance detected (ratio: {imbalance_ratio:.1f}:1)\")\n",
        "        print(\"   Consider collecting more data for underrepresented classes.\")\n",
        "    else:\n",
        "        print(f\"\\n\u2713 Class distribution is reasonably balanced (ratio: {imbalance_ratio:.1f}:1)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Split Data\n",
        "\n",
        "Split into training, validation, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'X_combined' in locals():\n",
        "    # Split: 70% train, 15% validation, 15% test\n",
        "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "        X_combined, y_combined,\n",
        "        test_size=0.15,\n",
        "        random_state=42,\n",
        "        stratify=np.argmax(y_combined, axis=1)\n",
        "    )\n",
        "    \n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_temp, y_temp,\n",
        "        test_size=0.176,  # 0.176 of 85% \u2248 15% of total\n",
        "        random_state=42,\n",
        "        stratify=np.argmax(y_temp, axis=1)\n",
        "    )\n",
        "    \n",
        "    print(f\"Training set:   {len(X_train)} samples ({len(X_train)/len(X_combined)*100:.1f}%)\")\n",
        "    print(f\"Validation set: {len(X_val)} samples ({len(X_val)/len(X_combined)*100:.1f}%)\")\n",
        "    print(f\"Test set:       {len(X_test)} samples ({len(X_test)/len(X_combined)*100:.1f}%)\")\n",
        "    print(f\"\\n\u2713 Data split complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Create Model\n",
        "\n",
        "Instantiate the CNN/LSTM architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model\n",
        "model = create_cnn_lstm_model(\n",
        "    input_shape=(50, 9),  # 50 timesteps, 9 features\n",
        "    num_classes=5,        # 5 gestures\n",
        "    cnn_filters=(64, 128),\n",
        "    lstm_units=(128, 64),\n",
        "    dense_units=64,\n",
        "    dropout_rate=0.3\n",
        ")\n",
        "\n",
        "print(\"\u2713 Model created\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Train Model\n",
        "\n",
        "Train with early stopping to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# Configure callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        '../models/cnn_lstm_best.h5',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "# Train model\n",
        "if 'X_train' in locals():\n",
        "    print(\"Starting training...\\n\")\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    print(\"\\n\u2713 Training complete\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f  No training data available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Visualize Training\n",
        "\n",
        "Plot training and validation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'history' in locals():\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # Plot accuracy\n",
        "    ax1.plot(history.history['accuracy'], label='Train')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation')\n",
        "    ax1.set_title('Model Accuracy')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "    \n",
        "    # Plot loss\n",
        "    ax2.plot(history.history['loss'], label='Train')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation')\n",
        "    ax2.set_title('Model Loss')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print final metrics\n",
        "    print(f\"\\nFinal Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
        "    print(f\"Final Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Evaluate on Test Set\n",
        "\n",
        "Final evaluation on held-out test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'X_test' in locals():\n",
        "    # Evaluate\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "    \n",
        "    # Predictions\n",
        "    y_pred = model.predict(X_test, verbose=0)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "    \n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(\n",
        "        y_true_classes,\n",
        "        y_pred_classes,\n",
        "        target_names=gesture_names\n",
        "    ))\n",
        "    \n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt='d',\n",
        "        cmap='Blues',\n",
        "        xticklabels=gesture_names,\n",
        "        yticklabels=gesture_names\n",
        "    )\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Save Model\n",
        "\n",
        "Save the trained model for deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save final model\n",
        "model_path = '../models/cnn_lstm_gesture.h5'\n",
        "save_model(model, model_path)\n",
        "\n",
        "print(f\"\\n\u2713 Model saved to {model_path}\")\n",
        "print(\"\\nReady for real-time integration!\")\n",
        "print(\"Next step: Use this model in src/udp_listener_v3.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Training complete! The model is now ready for real-time gesture recognition.\n",
        "\n",
        "**Next Steps:**\n",
        "1. Test the model with `src/udp_listener_v3.py`\n",
        "2. Collect more data if accuracy is insufficient\n",
        "3. Tune hyperparameters if needed\n",
        "4. Deploy to production\n",
        "\n",
        "**Expected Performance:**\n",
        "- Accuracy: 90-98%\n",
        "- Latency: 10-30ms per prediction\n",
        "- Model size: ~850 KB"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}