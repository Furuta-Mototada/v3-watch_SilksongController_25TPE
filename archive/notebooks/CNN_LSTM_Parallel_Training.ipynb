{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f978e085",
   "metadata": {},
   "source": [
    "# CNN/LSTM Parallel Two-Classifier Training\n",
    "\n",
    "**Parallel Architecture for Silksong Gesture Recognition**\n",
    "\n",
    "This notebook trains TWO CNN/LSTM models:\n",
    "1. **Binary Classifier**: Walk vs Idle (locomotion - 5s samples)\n",
    "2. **Multiclass Classifier**: Jump, Punch, Turn_Left, Turn_Right (actions - 1-2s samples)\n",
    "\n",
    "These run in **PARALLEL** for simultaneous detection (e.g., walk + jump).\n",
    "\n",
    "## Setup Requirements:\n",
    "1. ‚úÖ Enable GPU: Runtime > Change runtime type > GPU (T4 recommended)\n",
    "2. ‚úÖ Upload merged_training.zip to Google Drive\n",
    "3. ‚úÖ Unzip in: `My Drive/silksong_data/merged_training/`\n",
    "\n",
    "## Expected Training Time:\n",
    "- **With GPU (T4):** 30-60 minutes (2 models)\n",
    "- **Without GPU:** Not recommended\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff99b4cb",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive & Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80204d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n‚úÖ Google Drive mounted!\")\n",
    "print(\"Your data should be in: /content/drive/MyDrive/silksong_data/merged_training/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af8f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"\\nGPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"\\n‚úÖ GPU is enabled! Training will be fast.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No GPU detected. Enable GPU: Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5afb3b",
   "metadata": {},
   "source": [
    "## 2. Configure Data Paths & Architecture\n",
    "\n",
    "**CRITICAL**: Two separate models with different sample types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory in Google Drive\n",
    "DATA_DIR = '/content/drive/MyDrive/silksong_data/merged_training'\n",
    "\n",
    "# ==================== PARALLEL ARCHITECTURE ====================\n",
    "\n",
    "# BINARY CLASSIFIER: Locomotion states (5s samples, ~100-200 rows each)\n",
    "BINARY_GESTURES = ['idle', 'walk']\n",
    "BINARY_DATA_DIR = os.path.join(DATA_DIR, 'binary_classification')\n",
    "BINARY_WINDOW_SIZE = 100  # 2 seconds at 50Hz (from 5s samples)\n",
    "BINARY_STRIDE = 50        # 1 second stride\n",
    "\n",
    "# MULTICLASS CLASSIFIER: Action gestures (1-2s samples, ~40-80 rows each)\n",
    "MULTICLASS_GESTURES = ['jump', 'punch', 'turn_left', 'turn_right']\n",
    "MULTICLASS_DATA_DIR = os.path.join(DATA_DIR, 'multiclass_classification')\n",
    "MULTICLASS_WINDOW_SIZE = 50  # 1 second at 50Hz (from 1-2s samples)\n",
    "MULTICLASS_STRIDE = 25        # 0.5 second stride\n",
    "\n",
    "# Sensor features (merged data format)\n",
    "NUM_FEATURES = 10  # accel_x/y/z, gyro_x/y/z, rot_w/x/y/z\n",
    "\n",
    "print(\"üìä Training Configuration:\")\n",
    "print(f\"\\nBinary Classifier (Locomotion):\")\n",
    "print(f\"  Gestures: {BINARY_GESTURES}\")\n",
    "print(f\"  Window: {BINARY_WINDOW_SIZE} samples = {BINARY_WINDOW_SIZE/50:.1f}s\")\n",
    "print(f\"  Data: {BINARY_DATA_DIR}\")\n",
    "\n",
    "print(f\"\\nMulticlass Classifier (Actions):\")\n",
    "print(f\"  Gestures: {MULTICLASS_GESTURES}\")\n",
    "print(f\"  Window: {MULTICLASS_WINDOW_SIZE} samples = {MULTICLASS_WINDOW_SIZE/50:.1f}s\")\n",
    "print(f\"  Data: {MULTICLASS_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d715107b",
   "metadata": {},
   "source": [
    "## 3. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6583066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gesture_samples(data_dir, gestures, feature_cols=None):\n",
    "    \"\"\"\n",
    "    Load CSV files for each gesture class (merged format).\n",
    "\n",
    "    Args:\n",
    "        data_dir: Path to binary_classification or multiclass_classification folder\n",
    "        gestures: List of gesture names\n",
    "        feature_cols: Columns to use as features\n",
    "\n",
    "    Returns:\n",
    "        X: List of samples (each is a 2D array: timesteps √ó features)\n",
    "        y: List of labels (gesture indices)\n",
    "    \"\"\"\n",
    "    if feature_cols is None:\n",
    "        feature_cols = ['accel_x', 'accel_y', 'accel_z',\n",
    "                       'gyro_x', 'gyro_y', 'gyro_z',\n",
    "                       'rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "\n",
    "    all_samples = []\n",
    "    all_labels = []\n",
    "\n",
    "    for gesture_idx, gesture in enumerate(gestures):\n",
    "        gesture_path = Path(data_dir) / gesture\n",
    "\n",
    "        if not gesture_path.exists():\n",
    "            print(f\"‚ö†Ô∏è  Warning: {gesture} folder not found at {gesture_path}\")\n",
    "            continue\n",
    "\n",
    "        csv_files = list(gesture_path.glob(\"*.csv\"))\n",
    "        print(f\"üìÇ Loading {len(csv_files)} samples for '{gesture}'...\")\n",
    "\n",
    "        for csv_file in csv_files:\n",
    "            try:\n",
    "                df = pd.read_csv(csv_file)\n",
    "\n",
    "                # Extract features (merged format has all sensors in one row)\n",
    "                if all(col in df.columns for col in feature_cols):\n",
    "                    sample = df[feature_cols].values  # Shape: (n_timesteps, n_features)\n",
    "                    all_samples.append(sample)\n",
    "                    all_labels.append(gesture_idx)\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è  Skipping {csv_file.name}: missing columns\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading {csv_file.name}: {e}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Loaded {len(all_samples)} total samples\")\n",
    "    return all_samples, all_labels\n",
    "\n",
    "\n",
    "def create_windows(samples, labels, window_size, stride):\n",
    "    \"\"\"\n",
    "    Create sliding windows from variable-length samples.\n",
    "\n",
    "    Args:\n",
    "        samples: List of 2D arrays (each: timesteps √ó features)\n",
    "        labels: List of gesture indices\n",
    "        window_size: Number of timesteps per window\n",
    "        stride: Step size for sliding window\n",
    "\n",
    "    Returns:\n",
    "        X: Array of shape (n_windows, window_size, n_features)\n",
    "        y: Array of shape (n_windows,)\n",
    "    \"\"\"\n",
    "    X_windows = []\n",
    "    y_windows = []\n",
    "\n",
    "    for sample, label in zip(samples, labels):\n",
    "        # Slide window across this sample\n",
    "        for start_idx in range(0, len(sample) - window_size + 1, stride):\n",
    "            window = sample[start_idx:start_idx + window_size]\n",
    "            X_windows.append(window)\n",
    "            y_windows.append(label)\n",
    "\n",
    "    X = np.array(X_windows)\n",
    "    y = np.array(y_windows)\n",
    "\n",
    "    print(f\"\\nüìä Created {len(X)} windows from {len(samples)} samples\")\n",
    "    print(f\"   Window shape: {X.shape}\")\n",
    "    print(f\"   Label distribution: {np.bincount(y)}\")\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81e6f7",
   "metadata": {},
   "source": [
    "## 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb02e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_lstm_model(input_shape, num_classes, name=\"gesture_model\"):\n",
    "    \"\"\"\n",
    "    Create CNN/LSTM hybrid model.\n",
    "\n",
    "    Args:\n",
    "        input_shape: (window_size, num_features)\n",
    "        num_classes: Number of gesture classes\n",
    "        name: Model name\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        # Input layer\n",
    "        keras.Input(shape=input_shape, name='sensor_input'),\n",
    "\n",
    "        # CNN layers for feature extraction\n",
    "        layers.Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # LSTM layers for temporal patterns\n",
    "        layers.LSTM(128, return_sequences=True),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.LSTM(64),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # Dense classification layers\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Dense(num_classes, activation='softmax', name='output')\n",
    "    ], name=name)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7af75",
   "metadata": {},
   "source": [
    "## 5. Train Binary Classifier (Walk vs Idle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1cff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load binary data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BINARY CLASSIFIER TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "binary_samples, binary_labels = load_gesture_samples(\n",
    "    BINARY_DATA_DIR,\n",
    "    BINARY_GESTURES\n",
    ")\n",
    "\n",
    "# Create windows\n",
    "X_binary, y_binary = create_windows(\n",
    "    binary_samples,\n",
    "    binary_labels,\n",
    "    BINARY_WINDOW_SIZE,\n",
    "    BINARY_STRIDE\n",
    ")\n",
    "\n",
    "# Split train/test\n",
    "X_binary_train, X_binary_test, y_binary_train, y_binary_test = train_test_split(\n",
    "    X_binary, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Binary Split:\")\n",
    "print(f\"   Train: {len(X_binary_train)} windows\")\n",
    "print(f\"   Test:  {len(X_binary_test)} windows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719ad11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary model\n",
    "binary_model = create_cnn_lstm_model(\n",
    "    input_shape=(BINARY_WINDOW_SIZE, NUM_FEATURES),\n",
    "    num_classes=len(BINARY_GESTURES),\n",
    "    name=\"binary_classifier\"\n",
    ")\n",
    "\n",
    "binary_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1a0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "binary_class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_binary_train),\n",
    "    y=y_binary_train\n",
    ")\n",
    "binary_class_weights_dict = {i: w for i, w in enumerate(binary_class_weights)}\n",
    "\n",
    "print(f\"\\nClass weights: {binary_class_weights_dict}\")\n",
    "\n",
    "# Train binary model\n",
    "binary_history = binary_model.fit(\n",
    "    X_binary_train, y_binary_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    class_weight=binary_class_weights_dict,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5)\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate binary model\n",
    "binary_test_loss, binary_test_acc = binary_model.evaluate(X_binary_test, y_binary_test)\n",
    "print(f\"\\n‚úÖ Binary Test Accuracy: {binary_test_acc*100:.2f}%\")\n",
    "\n",
    "# Predictions\n",
    "y_binary_pred = np.argmax(binary_model.predict(X_binary_test), axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (Binary):\")\n",
    "print(classification_report(y_binary_test, y_binary_pred, target_names=BINARY_GESTURES))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_binary = confusion_matrix(y_binary_test, y_binary_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_binary, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=BINARY_GESTURES, yticklabels=BINARY_GESTURES)\n",
    "plt.title('Binary Classifier Confusion Matrix')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221cb7bb",
   "metadata": {},
   "source": [
    "## 6. Train Multiclass Classifier (Jump, Punch, Turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiclass data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MULTICLASS CLASSIFIER TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "multiclass_samples, multiclass_labels = load_gesture_samples(\n",
    "    MULTICLASS_DATA_DIR,\n",
    "    MULTICLASS_GESTURES\n",
    ")\n",
    "\n",
    "# Create windows\n",
    "X_multiclass, y_multiclass = create_windows(\n",
    "    multiclass_samples,\n",
    "    multiclass_labels,\n",
    "    MULTICLASS_WINDOW_SIZE,\n",
    "    MULTICLASS_STRIDE\n",
    ")\n",
    "\n",
    "# Split train/test\n",
    "X_multi_train, X_multi_test, y_multi_train, y_multi_test = train_test_split(\n",
    "    X_multiclass, y_multiclass, test_size=0.2, random_state=42, stratify=y_multiclass\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Multiclass Split:\")\n",
    "print(f\"   Train: {len(X_multi_train)} windows\")\n",
    "print(f\"   Test:  {len(X_multi_test)} windows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd3739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiclass model\n",
    "multiclass_model = create_cnn_lstm_model(\n",
    "    input_shape=(MULTICLASS_WINDOW_SIZE, NUM_FEATURES),\n",
    "    num_classes=len(MULTICLASS_GESTURES),\n",
    "    name=\"multiclass_classifier\"\n",
    ")\n",
    "\n",
    "multiclass_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3a4cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights\n",
    "multi_class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_multi_train),\n",
    "    y=y_multi_train\n",
    ")\n",
    "multi_class_weights_dict = {i: w for i, w in enumerate(multi_class_weights)}\n",
    "\n",
    "print(f\"\\nClass weights: {multi_class_weights_dict}\")\n",
    "\n",
    "# Train multiclass model\n",
    "multi_history = multiclass_model.fit(\n",
    "    X_multi_train, y_multi_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    class_weight=multi_class_weights_dict,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5)\n",
    "    ],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbfa342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate multiclass model\n",
    "multi_test_loss, multi_test_acc = multiclass_model.evaluate(X_multi_test, y_multi_test)\n",
    "print(f\"\\n‚úÖ Multiclass Test Accuracy: {multi_test_acc*100:.2f}%\")\n",
    "\n",
    "# Predictions\n",
    "y_multi_pred = np.argmax(multiclass_model.predict(X_multi_test), axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report (Multiclass):\")\n",
    "print(classification_report(y_multi_test, y_multi_pred, target_names=MULTICLASS_GESTURES))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_multi = confusion_matrix(y_multi_test, y_multi_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_multi, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=MULTICLASS_GESTURES, yticklabels=MULTICLASS_GESTURES)\n",
    "plt.title('Multiclass Classifier Confusion Matrix')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd58d2",
   "metadata": {},
   "source": [
    "## 7. Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91328ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Google Drive\n",
    "model_save_dir = '/content/drive/MyDrive/silksong_models'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "\n",
    "# Save binary model\n",
    "binary_model_path = os.path.join(model_save_dir, 'binary_cnn_lstm.h5')\n",
    "binary_model.save(binary_model_path)\n",
    "print(f\"‚úÖ Binary model saved: {binary_model_path}\")\n",
    "\n",
    "# Save multiclass model\n",
    "multi_model_path = os.path.join(model_save_dir, 'multiclass_cnn_lstm.h5')\n",
    "multiclass_model.save(multi_model_path)\n",
    "print(f\"‚úÖ Multiclass model saved: {multi_model_path}\")\n",
    "\n",
    "# Save gesture mappings\n",
    "import json\n",
    "\n",
    "mappings = {\n",
    "    'binary_gestures': BINARY_GESTURES,\n",
    "    'multiclass_gestures': MULTICLASS_GESTURES,\n",
    "    'binary_window_size': BINARY_WINDOW_SIZE,\n",
    "    'multiclass_window_size': MULTICLASS_WINDOW_SIZE,\n",
    "    'num_features': NUM_FEATURES\n",
    "}\n",
    "\n",
    "mapping_path = os.path.join(model_save_dir, 'model_config.json')\n",
    "with open(mapping_path, 'w') as f:\n",
    "    json.dump(mappings, f, indent=2)\n",
    "print(f\"‚úÖ Config saved: {mapping_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0024a",
   "metadata": {},
   "source": [
    "## 8. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot binary training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Binary accuracy\n",
    "ax1.plot(binary_history.history['accuracy'], label='Train')\n",
    "ax1.plot(binary_history.history['val_accuracy'], label='Validation')\n",
    "ax1.set_title('Binary Classifier Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Binary loss\n",
    "ax2.plot(binary_history.history['loss'], label='Train')\n",
    "ax2.plot(binary_history.history['val_loss'], label='Validation')\n",
    "ax2.set_title('Binary Classifier Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d69e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multiclass training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Multiclass accuracy\n",
    "ax1.plot(multi_history.history['accuracy'], label='Train')\n",
    "ax1.plot(multi_history.history['val_accuracy'], label='Validation')\n",
    "ax1.set_title('Multiclass Classifier Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Multiclass loss\n",
    "ax2.plot(multi_history.history['loss'], label='Train')\n",
    "ax2.plot(multi_history.history['val_loss'], label='Validation')\n",
    "ax2.set_title('Multiclass Classifier Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93422fad",
   "metadata": {},
   "source": [
    "## 9. Download Models to Local Machine\n",
    "\n",
    "**After training, download the models:**\n",
    "\n",
    "1. Go to Files tab (left sidebar)\n",
    "2. Navigate to `drive/MyDrive/silksong_models/`\n",
    "3. Download:\n",
    "   - `binary_cnn_lstm.h5`\n",
    "   - `multiclass_cnn_lstm.h5`\n",
    "   - `model_config.json`\n",
    "4. Place in your local `models/` directory\n",
    "\n",
    "**Or use Google Drive sync** to automatically sync to your computer.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "‚úÖ **Two models trained:**\n",
    "- Binary: Walk vs Idle (locomotion)\n",
    "- Multiclass: Jump, Punch, Turn_Left, Turn_Right (actions)\n",
    "\n",
    "‚úÖ **Parallel architecture** - Both run simultaneously in controller\n",
    "\n",
    "‚úÖ **Merged sensor data** - Clean, non-zero-inflated features\n",
    "\n",
    "‚úÖ **Expected accuracy**: 85-95% (vs 60-70% with old single model)\n",
    "\n",
    "**Next:** Test models with your controller! üéÆ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
