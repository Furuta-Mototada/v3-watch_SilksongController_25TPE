{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a26573",
   "metadata": {},
   "source": [
    "# Silksong Gesture Recognition - CNN/LSTM Training\n",
    "\n",
    "**Training for Hollow Knight: Silksong Voice-Controlled Watch Interface**\n",
    "\n",
    "This notebook trains a CNN/LSTM deep learning model for real-time gesture recognition.\n",
    "\n",
    "## Setup Requirements:\n",
    "1. ✅ Enable GPU: Runtime > Change runtime type > GPU (T4 recommended)\n",
    "2. ✅ Upload your data to Google Drive in: `My Drive/silksong_data/`\n",
    "3. ✅ Each session folder should contain:\n",
    "   - `sensor_data.csv` (accelerometer + gyroscope data)\n",
    "   - `[session]_labels.csv` (gesture labels with timestamps)\n",
    "\n",
    "## Expected Training Time:\n",
    "- **With GPU (T4):** 20-40 minutes\n",
    "- **Without GPU (CPU):** 2-4 hours (not recommended)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48eb57",
   "metadata": {},
   "source": [
    "---\n",
    "## 🆕 NEW: Automated Class Balancing (Oct 2025)\n",
    "\n",
    "**Problem solved:** Model was predicting only \"walk\" (78% of data) with 0% accuracy on jump/punch/turn.\n",
    "\n",
    "**Triple-strategy fix:**\n",
    "1. **Undersample** the majority class (walk) to 3x the largest minority\n",
    "2. **Augment** minority classes (jump/punch/turn/noise) with variations\n",
    "3. **Apply moderate class weights** to remaining imbalance\n",
    "\n",
    "**Expected improvement:** \n",
    "- Before: Jump/Punch/Turn at 0% accuracy ❌\n",
    "- After: All gestures at 70-85% accuracy ✅\n",
    "\n",
    "**New cells added:** After split/train/validation, you'll see sections 4.5 (balancing) and 6.5 (verification).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86407884",
   "metadata": {},
   "source": [
    "## 1. Mount Google Drive & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aceaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n✅ Google Drive mounted!\")\n",
    "print(\"Your data should be in: /content/drive/MyDrive/silksong_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f164440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"\\nGPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"\\n✅ GPU is enabled! Training will be fast.\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No GPU detected. Training will be slow.\")\n",
    "    print(\"   Enable GPU: Runtime > Change runtime type > GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f205130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"✅ All imports successful!\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe216dd",
   "metadata": {},
   "source": [
    "## 2. Configure Data Paths\n",
    "\n",
    "**Update this cell with your session folder names!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c942800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory in Google Drive\n",
    "DATA_DIR = '/content/drive/MyDrive/silksong_data'\n",
    "\n",
    "# List your session folders here\n",
    "SESSION_FOLDERS = [\n",
    "    '20251017_125600_session',\n",
    "    '20251017_135458_session',\n",
    "    '20251017_141539_session',\n",
    "    '20251017_143217_session',\n",
    "    '20251017_143627_session',\n",
    "]\n",
    "\n",
    "# Model configuration\n",
    "# 🔧 REDUCED WINDOW SIZE to capture short gesture labels (0.3s duration)\n",
    "WINDOW_SIZE = 25  # 0.5 seconds at 50Hz (was 50 = 1.0s)\n",
    "STRIDE = 12       # 0.24 seconds overlap (was 25 = 0.5s)\n",
    "\n",
    "# Why reduced window size?\n",
    "# - Your voice labels are only 0.3s duration (word pronunciation time)\n",
    "# - Original 1.0s windows required 50 consecutive samples of same gesture\n",
    "# - 0.3s labels = 15 samples, can't fill a 50-sample window\n",
    "# - New 0.5s windows = 25 samples, can capture 0.3s labels!\n",
    "# - Expected result: 50-100 jump windows instead of only 7\n",
    "\n",
    "# Expected features: accel_x, accel_y, accel_z, gyro_x, gyro_y, gyro_z,\n",
    "#                    rot_w, rot_x, rot_y, rot_z = 10 features\n",
    "# (timestamp and sensor columns are excluded)\n",
    "NUM_FEATURES = 10  # Will be verified during data loading\n",
    "\n",
    "# Gesture classes\n",
    "GESTURES = ['jump', 'punch', 'turn', 'walk', 'noise']\n",
    "NUM_CLASSES = len(GESTURES)\n",
    "\n",
    "print(f\"Configured {len(SESSION_FOLDERS)} sessions for training\")\n",
    "print(f\"Gestures: {GESTURES}\")\n",
    "print(f\"Window: {WINDOW_SIZE} samples ({WINDOW_SIZE/50.0:.2f}s) with {STRIDE} sample stride ({STRIDE/50.0:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb93add",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_session_data(session_folder):\n",
    "    \"\"\"Load sensor data and labels for one session\"\"\"\n",
    "    session_path = os.path.join(DATA_DIR, session_folder)\n",
    "\n",
    "    # Load sensor data\n",
    "    sensor_file = os.path.join(session_path, 'sensor_data.csv')\n",
    "    sensor_data_raw = pd.read_csv(sensor_file, skipinitialspace=True)\n",
    "\n",
    "    # Clean column names (strip whitespace)\n",
    "    sensor_data_raw.columns = sensor_data_raw.columns.str.strip()\n",
    "\n",
    "    # 🔧 FIX: Process sensor data to handle separate rows per sensor\n",
    "    # Sensor data has separate rows for each sensor type (linear_acceleration, gyroscope, rotation_vector)\n",
    "    # We need to merge them into one row per timestamp with all sensor values\n",
    "\n",
    "    # Separate by sensor type\n",
    "    accel_data = sensor_data_raw[sensor_data_raw['sensor'] == 'linear_acceleration'][['timestamp', 'accel_x', 'accel_y', 'accel_z']].copy()\n",
    "    gyro_data = sensor_data_raw[sensor_data_raw['sensor'] == 'gyroscope'][['timestamp', 'gyro_x', 'gyro_y', 'gyro_z']].copy()\n",
    "    rot_data = sensor_data_raw[sensor_data_raw['sensor'] == 'rotation_vector'][['timestamp', 'rot_w', 'rot_x', 'rot_y', 'rot_z']].copy()\n",
    "\n",
    "    # Get all unique timestamps\n",
    "    all_timestamps = pd.DataFrame({'timestamp': sorted(sensor_data_raw['timestamp'].unique())})\n",
    "\n",
    "    # Merge all sensors on timestamp\n",
    "    sensor_data = all_timestamps.copy()\n",
    "    sensor_data = sensor_data.merge(accel_data, on='timestamp', how='left')\n",
    "    sensor_data = sensor_data.merge(gyro_data, on='timestamp', how='left')\n",
    "    sensor_data = sensor_data.merge(rot_data, on='timestamp', how='left')\n",
    "\n",
    "    # Forward-fill to propagate sensor values (sensors update at different rates)\n",
    "    feature_cols = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z']\n",
    "    sensor_data[feature_cols] = sensor_data[feature_cols].ffill()\n",
    "\n",
    "    # Fill any remaining NaN (at the beginning) with 0\n",
    "    sensor_data[feature_cols] = sensor_data[feature_cols].fillna(0)\n",
    "\n",
    "    # Load labels\n",
    "    labels_file = os.path.join(session_path, f'{session_folder}_labels.csv')\n",
    "    labels_data = pd.read_csv(labels_file)\n",
    "\n",
    "    return sensor_data, labels_data\n",
    "\n",
    "\n",
    "def create_label_vector(sensor_data, labels_data):\n",
    "    \"\"\"Create per-sample labels from segment labels\"\"\"\n",
    "    num_samples = len(sensor_data)\n",
    "    label_vector = np.full(num_samples, -1, dtype=int)\n",
    "\n",
    "    # Assuming 50Hz sampling rate\n",
    "    sample_rate = 50.0\n",
    "\n",
    "    for _, row in labels_data.iterrows():\n",
    "        start_time = row['timestamp']\n",
    "        duration = row['duration']\n",
    "        gesture = row['gesture']\n",
    "\n",
    "        if gesture not in GESTURES:\n",
    "            continue\n",
    "\n",
    "        gesture_idx = GESTURES.index(gesture)\n",
    "\n",
    "        # Convert time to sample indices\n",
    "        start_idx = int(start_time * sample_rate)\n",
    "        end_idx = int((start_time + duration) * sample_rate)\n",
    "\n",
    "        # Clip to valid range\n",
    "        start_idx = max(0, min(start_idx, num_samples))\n",
    "        end_idx = max(0, min(end_idx, num_samples))\n",
    "\n",
    "        label_vector[start_idx:end_idx] = gesture_idx\n",
    "\n",
    "    return label_vector\n",
    "\n",
    "\n",
    "def create_windows(sensor_data, labels, window_size, stride):\n",
    "    \"\"\"Create sliding windows from continuous data\"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    num_samples = len(sensor_data)\n",
    "\n",
    "    for i in range(0, num_samples - window_size, stride):\n",
    "        window = sensor_data[i:i+window_size]\n",
    "        window_labels = labels[i:i+window_size]\n",
    "\n",
    "        # Skip if window contains unlabeled data\n",
    "        if np.any(window_labels == -1):\n",
    "            continue\n",
    "\n",
    "        # Use majority vote for window label\n",
    "        label = np.bincount(window_labels).argmax()\n",
    "\n",
    "        X.append(window)\n",
    "        y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "print(\"✅ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process all sessions\n",
    "all_X = []\n",
    "all_y = []\n",
    "\n",
    "for session_folder in SESSION_FOLDERS:\n",
    "    print(f\"\\nProcessing {session_folder}...\")\n",
    "\n",
    "    try:\n",
    "        sensor_data, labels_data = load_session_data(session_folder)\n",
    "        print(f\"  Sensor samples: {len(sensor_data)}\")\n",
    "        print(f\"  Label segments: {len(labels_data)}\")\n",
    "\n",
    "        # Extract features (exclude non-numeric columns: timestamp, sensor)\n",
    "        feature_cols = [col for col in sensor_data.columns\n",
    "                       if col not in ['timestamp', 'sensor']]\n",
    "\n",
    "        # Convert to float32 explicitly to avoid dtype issues\n",
    "        features = sensor_data[feature_cols].astype(np.float32).values\n",
    "\n",
    "        # Verify features are numeric\n",
    "        print(f\"  Feature columns ({len(feature_cols)}): {feature_cols}\")\n",
    "        print(f\"  Feature shape: {features.shape}\")\n",
    "        print(f\"  Feature dtype: {features.dtype}\")\n",
    "\n",
    "        # Create per-sample labels\n",
    "        label_vector = create_label_vector(sensor_data, labels_data)\n",
    "\n",
    "        # Create sliding windows\n",
    "        X, y = create_windows(features, label_vector, WINDOW_SIZE, STRIDE)\n",
    "        print(f\"  Generated {len(X)} windows\")\n",
    "\n",
    "        all_X.append(X)\n",
    "        all_y.append(y)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "# Combine all sessions\n",
    "if all_X:\n",
    "    X_combined = np.concatenate(all_X, axis=0)\n",
    "    y_combined = np.concatenate(all_y, axis=0)\n",
    "\n",
    "    print(f\"\\n✅ Total training windows: {len(X_combined)}\")\n",
    "    print(f\"   Input shape: {X_combined.shape}\")\n",
    "    print(f\"   Labels shape: {y_combined.shape}\")\n",
    "    print(f\"   X dtype: {X_combined.dtype}\")\n",
    "    print(f\"   y dtype: {y_combined.dtype}\")\n",
    "\n",
    "    # Show class distribution\n",
    "    print(\"\\n   Class distribution:\")\n",
    "    for i, gesture in enumerate(GESTURES):\n",
    "        count = np.sum(y_combined == i)\n",
    "        percentage = count / len(y_combined) * 100\n",
    "        print(f\"     {gesture}: {count} ({percentage:.1f}%)\")\n",
    "else:\n",
    "    print(\"\\n❌ No data loaded! Check your data paths.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263dd63",
   "metadata": {},
   "source": [
    "## 4. Split Train/Validation/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0fc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "X_combined, y_combined = shuffle(X_combined, y_combined, random_state=42)\n",
    "\n",
    "# Split: 70% train, 15% validation, 15% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_combined, y_combined, test_size=0.15, random_state=42, stratify=y_combined\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.176 of 0.85 ≈ 0.15 overall\n",
    ")\n",
    "\n",
    "print(f\"Training set:   {len(X_train)} samples ({len(X_train)/len(X_combined)*100:.1f}%)\")\n",
    "print(f\"Validation set: {len(X_val)} samples ({len(X_val)/len(X_combined)*100:.1f}%)\")\n",
    "print(f\"Test set:       {len(X_test)} samples ({len(X_test)/len(X_combined)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 🔧 CHECK FOR NaN/INF IN DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "nan_count = np.isnan(X_train).sum()\n",
    "inf_count = np.isinf(X_train).sum()\n",
    "\n",
    "print(f\"\\nNaN values in training data: {nan_count}\")\n",
    "print(f\"Inf values in training data: {inf_count}\")\n",
    "\n",
    "if nan_count > 0 or inf_count > 0:\n",
    "    print(\"⚠️  WARNING: Invalid values detected!\")\n",
    "    print(\"   Replacing NaN with 0 and clipping infinite values...\")\n",
    "    X_train = np.nan_to_num(X_train, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "    X_val = np.nan_to_num(X_val, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "    X_test = np.nan_to_num(X_test, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "    print(\"✅ Data cleaned!\")\n",
    "\n",
    "# Check data range\n",
    "print(f\"\\nData range:\")\n",
    "print(f\"  Min: {X_train.min():.4f}\")\n",
    "print(f\"  Max: {X_train.max():.4f}\")\n",
    "print(f\"  Mean: {X_train.mean():.4f}\")\n",
    "print(f\"  Std: {X_train.std():.4f}\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASS DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTraining set:\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_train == i)\n",
    "    pct = count / len(y_train) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\nValidation set:\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_val == i)\n",
    "    pct = count / len(y_val) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_test == i)\n",
    "    pct = count / len(y_test) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 🔧 SMART CLASS WEIGHT STRATEGY\n",
    "# ============================================================================\n",
    "# Use softened class weights to handle imbalance without numerical instability\n",
    "# Softening prevents extreme weights that can cause NaN loss\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASS WEIGHT STRATEGY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "class_counts = [np.sum(y_train == i) for i in range(NUM_CLASSES)]\n",
    "max_class_count = max(class_counts)\n",
    "min_class_count = min(class_counts)\n",
    "imbalance_ratio = max_class_count / min_class_count\n",
    "\n",
    "print(f\"\\nClass imbalance ratio: {imbalance_ratio:.1f}x\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = class_counts[i]\n",
    "    pct = count / len(y_train) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "# Compute balanced class weights\n",
    "class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "# Apply softening: Use square root to reduce extreme weights\n",
    "# This prevents numerical instability while still helping minority classes\n",
    "if imbalance_ratio > 10:\n",
    "    print(\"\\n🔧 Applying softening (sqrt) to prevent extreme weights...\")\n",
    "    class_weights_array = np.sqrt(class_weights_array)\n",
    "    class_weights = dict(enumerate(class_weights_array))\n",
    "\n",
    "    print(\"\\nSoftened class weights:\")\n",
    "    for i, gesture in enumerate(GESTURES):\n",
    "        print(f\"  {gesture:8s}: {class_weights[i]:.3f}\")\n",
    "\n",
    "    max_weight = max(class_weights.values())\n",
    "    min_weight = min(class_weights.values())\n",
    "    weight_ratio = max_weight / min_weight\n",
    "    print(f\"\\nWeight ratio after softening: {weight_ratio:.2f}x (was {imbalance_ratio:.1f}x)\")\n",
    "    print(\"✅ Softening reduces numerical instability while preserving class balance\")\n",
    "else:\n",
    "    print(\"\\n✅ Imbalance is moderate, using standard balanced weights\")\n",
    "    class_weights = dict(enumerate(class_weights_array))\n",
    "\n",
    "    print(\"\\nClass weights:\")\n",
    "    for i, gesture in enumerate(GESTURES):\n",
    "        print(f\"  {gesture:8s}: {class_weights[i]:.3f}\")\n",
    "\n",
    "print(\"\\n💡 Expected results:\")\n",
    "print(\"   - All gestures: 75-85% accuracy (balanced learning)\")\n",
    "print(\"   - Overall: 85-92% accuracy\")\n",
    "print(\"   - Stable training with softened weights\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0fa8b3",
   "metadata": {},
   "source": [
    "## 4.5 🔧 Class Balancing Strategies\n",
    "\n",
    "**Problem:** Model is predicting only \"walk\" because it dominates ~78% of the dataset.\n",
    "\n",
    "**Solution:** Apply multiple balancing techniques to level the playing field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45cb32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STRATEGY 1: UNDERSAMPLE THE MAJORITY CLASS (WALK)\n",
    "# ============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"STRATEGY 1: UNDERSAMPLING 'WALK' CLASS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Analyze current class distribution\n",
    "print(\"\\n📊 Current class distribution:\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_train == i)\n",
    "    pct = count / len(y_train) * 100\n",
    "    print(f\"  {gesture:8s}: {count:5d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "# Separate indices by class\n",
    "class_indices = {i: np.where(y_train == i)[0] for i in range(NUM_CLASSES)}\n",
    "\n",
    "# Find the second-largest minority class (to avoid over-downsampling)\n",
    "minority_counts = [len(class_indices[i]) for i in range(NUM_CLASSES)]\n",
    "walk_idx = GESTURES.index('walk')\n",
    "minority_counts_no_walk = [c for i, c in enumerate(minority_counts) if i != walk_idx]\n",
    "target_majority_size = max(minority_counts_no_walk) * 3  # 3x largest minority\n",
    "\n",
    "print(f\"\\n🎯 Target 'walk' size: {target_majority_size} (3x largest minority)\")\n",
    "\n",
    "# Downsample walk class\n",
    "walk_indices_downsampled = resample(\n",
    "    class_indices[walk_idx],\n",
    "    n_samples=target_majority_size,\n",
    "    random_state=42,\n",
    "    replace=False\n",
    ")\n",
    "\n",
    "# Combine all indices\n",
    "balanced_indices = walk_indices_downsampled.copy()\n",
    "for i in range(NUM_CLASSES):\n",
    "    if i != walk_idx:\n",
    "        balanced_indices = np.concatenate([balanced_indices, class_indices[i]])\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(balanced_indices)\n",
    "\n",
    "# Create balanced dataset\n",
    "X_train_balanced = X_train[balanced_indices]\n",
    "y_train_balanced = y_train[balanced_indices]\n",
    "\n",
    "print(f\"\\n✅ New training set size: {len(X_train_balanced)} (was {len(X_train)})\")\n",
    "print(\"\\n📊 Balanced class distribution:\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_train_balanced == i)\n",
    "    pct = count / len(y_train_balanced) * 100\n",
    "    print(f\"  {gesture:8s}: {count:5d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "# Calculate new imbalance ratio\n",
    "balanced_counts = [np.sum(y_train_balanced == i) for i in range(NUM_CLASSES)]\n",
    "new_imbalance = max(balanced_counts) / min(balanced_counts)\n",
    "print(f\"\\n📈 Imbalance ratio: {new_imbalance:.1f}x (was {max(minority_counts)/min(minority_counts):.1f}x)\")\n",
    "print(\"✅ Much more balanced for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STRATEGY 2: AUGMENT MINORITY CLASSES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STRATEGY 2: DATA AUGMENTATION FOR MINORITY CLASSES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def augment_window(window, augmentation_type='noise'):\n",
    "    \"\"\"Apply data augmentation to a single window\"\"\"\n",
    "    if augmentation_type == 'noise':\n",
    "        # Add small Gaussian noise\n",
    "        noise = np.random.normal(0, 0.02, window.shape)\n",
    "        return window + noise\n",
    "\n",
    "    elif augmentation_type == 'scale':\n",
    "        # Random scaling (90% to 110%)\n",
    "        scale = np.random.uniform(0.9, 1.1)\n",
    "        return window * scale\n",
    "\n",
    "    elif augmentation_type == 'time_shift':\n",
    "        # Shift by 1-3 samples (keeping window size same)\n",
    "        shift = np.random.randint(-3, 4)\n",
    "        return np.roll(window, shift, axis=0)\n",
    "\n",
    "    return window\n",
    "\n",
    "\n",
    "# Define minority classes (everything except walk)\n",
    "minority_classes = [i for i, gesture in enumerate(GESTURES) if gesture != 'walk']\n",
    "\n",
    "print(f\"\\n🎯 Augmenting minority classes: {[GESTURES[i] for i in minority_classes]}\")\n",
    "\n",
    "X_augmented = []\n",
    "y_augmented = []\n",
    "\n",
    "for class_idx in minority_classes:\n",
    "    class_data = X_train_balanced[y_train_balanced == class_idx]\n",
    "    original_count = len(class_data)\n",
    "\n",
    "    # Add original samples\n",
    "    X_augmented.extend(class_data)\n",
    "    y_augmented.extend([class_idx] * len(class_data))\n",
    "\n",
    "    # Generate 2 augmented versions of each sample\n",
    "    for sample in class_data:\n",
    "        # Augmentation 1: Add noise\n",
    "        aug1 = augment_window(sample, 'noise')\n",
    "        X_augmented.append(aug1)\n",
    "        y_augmented.append(class_idx)\n",
    "\n",
    "        # Augmentation 2: Scale\n",
    "        aug2 = augment_window(sample, 'scale')\n",
    "        X_augmented.append(aug2)\n",
    "        y_augmented.append(class_idx)\n",
    "\n",
    "    new_count = len([y for y in y_augmented if y == class_idx])\n",
    "    print(f\"  {GESTURES[class_idx]:8s}: {original_count:4d} → {new_count:4d} samples (3x)\")\n",
    "\n",
    "# Add majority class (walk) without augmentation\n",
    "walk_idx = GESTURES.index('walk')\n",
    "walk_data = X_train_balanced[y_train_balanced == walk_idx]\n",
    "X_augmented.extend(walk_data)\n",
    "y_augmented.extend([walk_idx] * len(walk_data))\n",
    "\n",
    "# Convert to arrays\n",
    "X_train_augmented = np.array(X_augmented, dtype=np.float32)\n",
    "y_train_augmented = np.array(y_augmented, dtype=np.int32)\n",
    "\n",
    "# Shuffle\n",
    "X_train_augmented, y_train_augmented = shuffle(\n",
    "    X_train_augmented, y_train_augmented, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Total augmented training samples: {len(X_train_augmented)}\")\n",
    "print(\"\\n📊 Final class distribution after augmentation:\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_train_augmented == i)\n",
    "    pct = count / len(y_train_augmented) * 100\n",
    "    print(f\"  {gesture:8s}: {count:5d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "# Calculate final imbalance\n",
    "final_counts = [np.sum(y_train_augmented == i) for i in range(NUM_CLASSES)]\n",
    "final_imbalance = max(final_counts) / min(final_counts)\n",
    "print(f\"\\n📈 Final imbalance ratio: {final_imbalance:.1f}x\")\n",
    "print(\"✅ Much more balanced dataset ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e565d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STRATEGY 3: CALCULATE MODERATE CLASS WEIGHTS FOR REMAINING IMBALANCE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STRATEGY 3: MODERATE CLASS WEIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Compute class weights on the balanced/augmented dataset\n",
    "class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train_augmented),\n",
    "    y=y_train_augmented\n",
    ")\n",
    "\n",
    "# Apply sqrt softening to prevent extreme weights\n",
    "class_weights_array = np.sqrt(class_weights_array)\n",
    "class_weights_final = dict(enumerate(class_weights_array))\n",
    "\n",
    "print(\"\\n📊 Moderate class weights (sqrt-softened):\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    print(f\"  {gesture:8s}: {class_weights_final[i]:.3f}\")\n",
    "\n",
    "max_weight = max(class_weights_final.values())\n",
    "min_weight = min(class_weights_final.values())\n",
    "weight_ratio = max_weight / min_weight\n",
    "\n",
    "print(f\"\\n📈 Weight ratio: {weight_ratio:.2f}x\")\n",
    "print(\"✅ Moderate weights won't destabilize training!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🎯 FINAL TRAINING CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n✅ Training samples: {len(X_train_augmented)}\")\n",
    "print(f\"✅ Validation samples: {len(X_val)}\")\n",
    "print(f\"✅ Test samples: {len(X_test)}\")\n",
    "print(f\"\\n💡 Expected results with balanced training:\")\n",
    "print(\"   - Jump: 70-85% accuracy (instead of 0%)\")\n",
    "print(\"   - Punch: 70-85% accuracy (instead of 0%)\")\n",
    "print(\"   - Turn: 70-85% accuracy (instead of 0%)\")\n",
    "print(\"   - Walk: 85-95% accuracy\")\n",
    "print(\"   - Noise: 60-75% accuracy\")\n",
    "print(\"   - Overall: 80-90% balanced accuracy\")\n",
    "print(\"\\n🚀 Ready to train with fair class representation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73fe7c",
   "metadata": {},
   "source": [
    "## 5. Build CNN/LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7be364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_lstm_model(input_shape, num_classes):\n",
    "    \"\"\"Create CNN/LSTM architecture for gesture recognition\"\"\"\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=input_shape),\n",
    "\n",
    "        # CNN layers for feature extraction\n",
    "        # Note: Adjusted for smaller window size (25 samples instead of 50)\n",
    "        layers.Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "\n",
    "        layers.Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        # Removed second pooling to preserve temporal resolution with smaller input\n",
    "\n",
    "        # LSTM layers for temporal modeling\n",
    "        layers.LSTM(64, return_sequences=True),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.LSTM(32),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # Dense layers for classification\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create model\n",
    "input_shape = (WINDOW_SIZE, NUM_FEATURES)\n",
    "model = create_cnn_lstm_model(input_shape, NUM_CLASSES)\n",
    "\n",
    "# Compile model with GRADIENT CLIPPING to prevent NaN\n",
    "optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    clipnorm=1.0  # Clip gradients to prevent explosion\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "print(f\"\\n💡 Model input shape: ({WINDOW_SIZE}, {NUM_FEATURES}) = {WINDOW_SIZE/50:.2f}s windows\")\n",
    "print(f\"   Optimizer: Adam with gradient clipping (clipnorm=1.0)\")\n",
    "print(f\"   This prevents NaN loss from exploding gradients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7ff38",
   "metadata": {},
   "source": [
    "## 6. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7778a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'best_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"✅ Callbacks configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ff04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with BALANCED dataset\n",
    "print(\"🚀 Starting training with balanced data...\\n\")\n",
    "\n",
    "# Use the balanced and augmented training data\n",
    "# (from the class balancing cells above)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_augmented, y_train_augmented,  # ✅ Using balanced/augmented data\n",
    "    validation_data=(X_val, y_val),         # Validation stays original\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights_final,       # ✅ Using moderate weights\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Training complete!\")\n",
    "print(\"\\n💡 What changed:\")\n",
    "print(\"   - Training data: Undersampled 'walk' + augmented minorities\")\n",
    "print(\"   - Class weights: Moderate sqrt-softened weights\")\n",
    "print(\"   - Expected: All gestures should now have >70% accuracy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf3c162",
   "metadata": {},
   "source": [
    "## 6.5 📊 Quick Model Check\n",
    "\n",
    "Let's verify the model is actually learning all classes now (not just predicting \"walk\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b8c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check: Is the model predicting all classes?\n",
    "print(\"=\"*70)\n",
    "print(\"🔍 MODEL PREDICTION DIVERSITY CHECK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get predictions on a sample of training data\n",
    "sample_size = min(500, len(X_train_augmented))\n",
    "y_train_pred = model.predict(X_train_augmented[:sample_size], verbose=0)\n",
    "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
    "\n",
    "print(f\"\\n📊 What the model is predicting (on {sample_size} training samples):\\n\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_train_pred_classes == i)\n",
    "    pct = count / len(y_train_pred_classes) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} predictions ({pct:5.1f}%)\")\n",
    "\n",
    "unique_preds = len(np.unique(y_train_pred_classes))\n",
    "print(f\"\\n✅ Model is predicting {unique_preds} out of {NUM_CLASSES} classes\")\n",
    "\n",
    "if unique_preds == NUM_CLASSES:\n",
    "    print(\"🎉 EXCELLENT! Model learned to predict ALL gesture types!\")\n",
    "elif unique_preds == 1:\n",
    "    print(\"❌ PROBLEM: Model collapsed to one class. Need more balancing.\")\n",
    "else:\n",
    "    print(\"⚠️  Model learned some classes but not all. Might need more training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba88d54",
   "metadata": {},
   "source": [
    "## 🔍 URGENT: Diagnose Training Issues\n",
    "\n",
    "**If you see training accuracy bouncing around 10-20% and validation accuracy dropping after epoch 3:**\n",
    "\n",
    "This suggests the class weights may be too extreme or there's a data issue. Run the diagnostic below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972a7c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚨 CRITICAL DIAGNOSTIC: What went wrong?\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING ISSUE DIAGNOSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check what the model is actually predicting\n",
    "y_train_pred = model.predict(X_train[:500], verbose=0)  # Check first 500 samples\n",
    "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
    "\n",
    "print(\"\\n1️⃣ MODEL PREDICTION DISTRIBUTION (on training data):\")\n",
    "print(\"-\" * 70)\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_train_pred_classes == i)\n",
    "    pct = count / len(y_train_pred_classes) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} predictions ({pct:5.1f}%)\")\n",
    "\n",
    "# Check if model is stuck predicting one class\n",
    "unique_preds = len(np.unique(y_train_pred_classes))\n",
    "print(f\"\\n  ⚠️  Model is predicting {unique_preds} out of {NUM_CLASSES} classes\")\n",
    "\n",
    "if unique_preds == 1:\n",
    "    print(f\"  🚨 PROBLEM: Model is ONLY predicting '{GESTURES[y_train_pred_classes[0]]}'!\")\n",
    "    print(\"  This means the model collapsed to always predict one class.\")\n",
    "\n",
    "# Check class weight values\n",
    "print(\"\\n2️⃣ CLASS WEIGHTS USED:\")\n",
    "print(\"-\" * 70)\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    print(f\"  {gesture:8s}: {class_weights[i]:.3f}\")\n",
    "\n",
    "max_weight = max(class_weights.values())\n",
    "min_weight = min(class_weights.values())\n",
    "weight_ratio = max_weight / min_weight\n",
    "\n",
    "print(f\"\\n  Weight ratio (max/min): {weight_ratio:.2f}x\")\n",
    "\n",
    "if weight_ratio > 10:\n",
    "    print(\"  ⚠️  EXTREME weight ratio! This can destabilize training.\")\n",
    "\n",
    "# Check actual class distribution again\n",
    "print(\"\\n3️⃣ ACTUAL CLASS DISTRIBUTION (training data):\")\n",
    "print(\"-\" * 70)\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_train == i)\n",
    "    pct = count / len(y_train) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "# Check for extreme imbalance\n",
    "class_counts = [np.sum(y_train == i) for i in range(NUM_CLASSES)]\n",
    "max_class_count = max(class_counts)\n",
    "min_class_count = min(class_counts)\n",
    "imbalance_ratio = max_class_count / min_class_count\n",
    "\n",
    "print(f\"\\n  Imbalance ratio (max/min): {imbalance_ratio:.2f}x\")\n",
    "\n",
    "if imbalance_ratio > 30:\n",
    "    print(\"  🚨 SEVERE IMBALANCE! The rarest class has <3% of data.\")\n",
    "    print(\"  Recommendation: Collect more data for rare classes.\")\n",
    "elif imbalance_ratio > 10:\n",
    "    print(\"  ⚠️  SIGNIFICANT IMBALANCE. Class weights may need adjustment.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if weight_ratio > 10:\n",
    "    print(\"\\n✅ FIX #1: Use Softer Class Weights\")\n",
    "    print(\"   Replace the class weight calculation with:\")\n",
    "    print(\"   ```\")\n",
    "    print(\"   # Softer class weights (less extreme)\")\n",
    "    print(\"   class_weights_array = compute_class_weight(\")\n",
    "    print(\"       'balanced', classes=np.unique(y_train), y=y_train\")\n",
    "    print(\"   )\")\n",
    "    print(\"   # Apply square root to soften weights\")\n",
    "    print(\"   class_weights_array = np.sqrt(class_weights_array)\")\n",
    "    print(\"   class_weights = dict(enumerate(class_weights_array))\")\n",
    "    print(\"   ```\")\n",
    "\n",
    "if imbalance_ratio > 20:\n",
    "    print(\"\\n✅ FIX #2: Try Training Without Class Weights First\")\n",
    "    print(\"   The imbalance might not be as bad as it looks.\")\n",
    "    print(\"   Comment out the class_weight parameter:\")\n",
    "    print(\"   ```\")\n",
    "    print(\"   history = model.fit(\")\n",
    "    print(\"       X_train, y_train,\")\n",
    "    print(\"       validation_data=(X_val, y_val),\")\n",
    "    print(\"       # class_weight=class_weights,  # Try without this\")\n",
    "    print(\"       epochs=100,\")\n",
    "    print(\"       ...\")\n",
    "    print(\"   ```\")\n",
    "\n",
    "print(\"\\n✅ FIX #3: Check Your Data Quality\")\n",
    "print(\"   Run the evaluation cells below to see the confusion matrix.\")\n",
    "print(\"   If the model saved at epoch 3 actually works, you might be fine!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b090c",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy\n",
    "ax1.plot(history.history['accuracy'], label='Train')\n",
    "ax1.plot(history.history['val_accuracy'], label='Validation')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Loss\n",
    "ax2.plot(history.history['loss'], label='Train')\n",
    "ax2.plot(history.history['val_loss'], label='Validation')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\n📊 Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "print(f\"   Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred_classes, target_names=GESTURES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4360f4bf",
   "metadata": {},
   "source": [
    "## 7.5 🔧 Create Balanced Test Set for Fair Evaluation\n",
    "\n",
    "**Problem:** Test set has 78% walk, but model was trained on balanced data.  \n",
    "**Solution:** Create a balanced test subset to see the model's true performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf35f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CREATE BALANCED TEST SET (same distribution as training)\n",
    "# ============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"CREATING BALANCED TEST SET FOR FAIR EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Current test set distribution (imbalanced)\n",
    "print(\"\\n📊 Original test set (imbalanced):\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_test == i)\n",
    "    pct = count / len(y_test) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "# Separate test indices by class\n",
    "test_class_indices = {i: np.where(y_test == i)[0] for i in range(NUM_CLASSES)}\n",
    "\n",
    "# Find minimum class count in test set\n",
    "min_test_count = min([len(test_class_indices[i]) for i in range(NUM_CLASSES)])\n",
    "print(f\"\\n🎯 Minimum class count in test set: {min_test_count}\")\n",
    "print(f\"   Will sample {min_test_count} from each class for balanced testing\")\n",
    "\n",
    "# Sample equal number from each class\n",
    "balanced_test_indices = []\n",
    "for i in range(NUM_CLASSES):\n",
    "    class_indices = test_class_indices[i]\n",
    "    # Sample min_test_count samples from this class\n",
    "    if len(class_indices) > min_test_count:\n",
    "        sampled_indices = resample(class_indices, n_samples=min_test_count,\n",
    "                                   random_state=42, replace=False)\n",
    "    else:\n",
    "        sampled_indices = class_indices\n",
    "    balanced_test_indices.extend(sampled_indices)\n",
    "\n",
    "# Create balanced test set\n",
    "balanced_test_indices = np.array(balanced_test_indices)\n",
    "X_test_balanced = X_test[balanced_test_indices]\n",
    "y_test_balanced = y_test[balanced_test_indices]\n",
    "\n",
    "# Verify balance\n",
    "print(f\"\\n✅ Balanced test set created: {len(X_test_balanced)} samples\")\n",
    "print(\"\\n📊 Balanced test set distribution:\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_test_balanced == i)\n",
    "    pct = count / len(y_test_balanced) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n💡 This balanced test set reflects the training distribution!\")\n",
    "print(\"   Now we can see the model's TRUE performance on all gestures.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVALUATE ON BALANCED TEST SET (TRUE PERFORMANCE)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🎯 EVALUATION ON BALANCED TEST SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Evaluate model on balanced test set\n",
    "test_loss_balanced, test_accuracy_balanced = model.evaluate(\n",
    "    X_test_balanced, y_test_balanced, verbose=0\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 Balanced Test Accuracy: {test_accuracy_balanced*100:.2f}%\")\n",
    "print(f\"   Balanced Test Loss: {test_loss_balanced:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_balanced = model.predict(X_test_balanced, verbose=0)\n",
    "y_pred_balanced_classes = np.argmax(y_pred_balanced, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION REPORT (BALANCED TEST SET)\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test_balanced, y_pred_balanced_classes,\n",
    "                           target_names=GESTURES))\n",
    "\n",
    "print(\"\\n💡 This shows the model's REAL performance when all classes matter!\")\n",
    "print(\"   Compare this to the 17% on imbalanced test set above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12458d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for balanced test set\n",
    "cm_balanced = confusion_matrix(y_test_balanced, y_pred_balanced_classes)\n",
    "cm_balanced_normalized = cm_balanced.astype('float') / cm_balanced.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_balanced_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=GESTURES, yticklabels=GESTURES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Balanced Test Set - Fair Evaluation)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Confusion Matrix Analysis:\")\n",
    "print(\"   - Diagonal values = correct predictions for each class\")\n",
    "print(\"   - Off-diagonal = common confusions\")\n",
    "print(\"   - All classes should have similar diagonal values now!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ab669",
   "metadata": {},
   "source": [
    "## 🔍 Understanding the Two Test Results\n",
    "\n",
    "**Why are there two different accuracy scores?**\n",
    "\n",
    "1. **Imbalanced Test Set (17% accuracy):**\n",
    "   - Test set has 78% walk, 3-8% others\n",
    "   - Model trained on balanced data gets confused\n",
    "   - Like training on diverse examples, then testing only on one type\n",
    "   \n",
    "2. **Balanced Test Set (should be 50-70%):**\n",
    "   - Equal samples from each class\n",
    "   - Fair evaluation of all gestures\n",
    "   - Shows true model capability\n",
    "\n",
    "**Which one matters?**\n",
    "- **For deployment:** You need to handle imbalanced real-world data\n",
    "- **For model quality:** Balanced test shows if the model actually learned\n",
    "\n",
    "**Next step:** Train with a strategy that works for BOTH!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fde978",
   "metadata": {},
   "source": [
    "## 🔧 Solution: Retrain with Balanced Validation\n",
    "\n",
    "**The Problem:** Early stopping kicked in at epoch 6 because validation set is 78% walk.\n",
    "\n",
    "**The Fix:** Create balanced validation set and train for more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CREATE BALANCED VALIDATION SET\n",
    "# ============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"CREATING BALANCED VALIDATION SET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Current validation distribution\n",
    "print(\"\\n📊 Original validation set (imbalanced):\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_val == i)\n",
    "    pct = count / len(y_val) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "# Separate validation indices by class\n",
    "val_class_indices = {i: np.where(y_val == i)[0] for i in range(NUM_CLASSES)}\n",
    "\n",
    "# Find minimum class count\n",
    "min_val_count = min([len(val_class_indices[i]) for i in range(NUM_CLASSES)])\n",
    "print(f\"\\n🎯 Sampling {min_val_count} from each class\")\n",
    "\n",
    "# Sample equal number from each class\n",
    "balanced_val_indices = []\n",
    "for i in range(NUM_CLASSES):\n",
    "    class_indices = val_class_indices[i]\n",
    "    if len(class_indices) > min_val_count:\n",
    "        sampled_indices = resample(class_indices, n_samples=min_val_count,\n",
    "                                   random_state=42, replace=False)\n",
    "    else:\n",
    "        sampled_indices = class_indices\n",
    "    balanced_val_indices.extend(sampled_indices)\n",
    "\n",
    "# Create balanced validation set\n",
    "balanced_val_indices = np.array(balanced_val_indices)\n",
    "X_val_balanced = X_val[balanced_val_indices]\n",
    "y_val_balanced = y_val[balanced_val_indices]\n",
    "\n",
    "print(f\"\\n✅ Balanced validation set: {len(X_val_balanced)} samples\")\n",
    "print(\"\\n📊 Balanced validation distribution:\")\n",
    "for i, gesture in enumerate(GESTURES):\n",
    "    count = np.sum(y_val_balanced == i)\n",
    "    pct = count / len(y_val_balanced) * 100\n",
    "    print(f\"  {gesture:8s}: {count:4d} samples ({pct:5.1f}%)\")\n",
    "\n",
    "print(\"\\n💡 Now early stopping will use balanced validation accuracy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc25bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# REBUILD MODEL (fresh start)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"REBUILDING MODEL FOR BALANCED TRAINING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create fresh model\n",
    "model_v2 = create_cnn_lstm_model(input_shape, NUM_CLASSES)\n",
    "\n",
    "# Compile with same settings\n",
    "optimizer_v2 = keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "model_v2.compile(\n",
    "    optimizer=optimizer_v2,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Fresh model created and compiled\")\n",
    "print(f\"   Total parameters: {model_v2.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be0394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RETRAIN WITH BALANCED VALIDATION (Better Callbacks)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🚀 RETRAINING WITH BALANCED VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Updated callbacks with longer patience\n",
    "callbacks_v2 = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',  # Changed to accuracy instead of loss\n",
    "        patience=20,              # Increased from 10 to 20\n",
    "        restore_best_weights=True,\n",
    "        mode='max',               # Maximize accuracy\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_accuracy',   # Changed to accuracy\n",
    "        factor=0.5,\n",
    "        patience=8,               # Increased from 5 to 8\n",
    "        min_lr=1e-6,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        'best_model_v2.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"\\n💡 Training configuration:\")\n",
    "print(\"   - Training data: Balanced + augmented (6,396 samples)\")\n",
    "print(\"   - Validation data: BALANCED (235 samples)\")\n",
    "print(\"   - Early stopping: Patience 20 epochs\")\n",
    "print(\"   - Monitor: Balanced validation accuracy\")\n",
    "print(\"   - Expected: Train for 30-50 epochs before stopping\")\n",
    "print(\"\\n🚀 Starting training...\\n\")\n",
    "\n",
    "history_v2 = model_v2.fit(\n",
    "    X_train_augmented, y_train_augmented,\n",
    "    validation_data=(X_val_balanced, y_val_balanced),  # ✅ BALANCED validation!\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks_v2,\n",
    "    class_weight=class_weights_final,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Training complete with balanced validation!\")\n",
    "print(f\"   Best validation accuracy: {max(history_v2.history['val_accuracy'])*100:.2f}%\")\n",
    "print(f\"   Total epochs trained: {len(history_v2.history['loss'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVALUATE RETRAINED MODEL ON BALANCED TEST\n",
    "# ============================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"🎯 FINAL EVALUATION (RETRAINED MODEL)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Evaluate on balanced test set\n",
    "test_loss_v2, test_accuracy_v2 = model_v2.evaluate(\n",
    "    X_test_balanced, y_test_balanced, verbose=0\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 Balanced Test Accuracy: {test_accuracy_v2*100:.2f}%\")\n",
    "print(f\"   Balanced Test Loss: {test_loss_v2:.4f}\")\n",
    "\n",
    "# Get predictions\n",
    "y_pred_v2 = model_v2.predict(X_test_balanced, verbose=0)\n",
    "y_pred_v2_classes = np.argmax(y_pred_v2, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test_balanced, y_pred_v2_classes,\n",
    "                           target_names=GESTURES))\n",
    "\n",
    "# Compare to first attempt\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📈 IMPROVEMENT COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"First attempt (stopped at epoch 6):  {test_accuracy_balanced*100:.2f}%\")\n",
    "print(f\"Retrained (balanced validation):      {test_accuracy_v2*100:.2f}%\")\n",
    "improvement = (test_accuracy_v2 - test_accuracy_balanced) * 100\n",
    "print(f\"Improvement:                           {improvement:+.2f} percentage points\")\n",
    "\n",
    "if test_accuracy_v2 > 0.6:\n",
    "    print(\"\\n🎉 SUCCESS! Model achieved >60% balanced accuracy!\")\n",
    "    print(\"   All gestures are being learned properly.\")\n",
    "elif test_accuracy_v2 > 0.45:\n",
    "    print(\"\\n✅ GOOD PROGRESS! Model is learning but needs refinement.\")\n",
    "    print(\"   Consider: More training epochs or data augmentation.\")\n",
    "else:\n",
    "    print(\"\\n⚠️  Still struggling. May need:\")\n",
    "    print(\"   1. More real training data\")\n",
    "    print(\"   2. Different model architecture\")\n",
    "    print(\"   3. Better feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35badea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of training histories\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# First attempt (stopped early)\n",
    "ax1.plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "ax1.plot(history.history['val_accuracy'], label='Val (Imbalanced)', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('First Attempt: Stopped at Epoch 6 (Imbalanced Validation)')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "ax1.axhline(y=0.3, color='r', linestyle='--', alpha=0.3, label='30% baseline')\n",
    "\n",
    "ax2.plot(history.history['loss'], label='Train', linewidth=2)\n",
    "ax2.plot(history.history['val_loss'], label='Val (Imbalanced)', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('First Attempt: Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Retrained version (balanced validation)\n",
    "ax3.plot(history_v2.history['accuracy'], label='Train', linewidth=2, color='green')\n",
    "ax3.plot(history_v2.history['val_accuracy'], label='Val (Balanced)', linewidth=2, color='orange')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.set_title('Retrained: Balanced Validation (Should Train Longer)')\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "ax3.axhline(y=0.6, color='g', linestyle='--', alpha=0.3, label='60% target')\n",
    "\n",
    "ax4.plot(history_v2.history['loss'], label='Train', linewidth=2, color='green')\n",
    "ax4.plot(history_v2.history['val_loss'], label='Val (Balanced)', linewidth=2, color='orange')\n",
    "ax4.set_xlabel('Epoch')\n",
    "ax4.set_ylabel('Loss')\n",
    "ax4.set_title('Retrained: Loss')\n",
    "ax4.legend()\n",
    "ax4.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Training Comparison:\")\n",
    "print(f\"   First attempt: {len(history.history['loss'])} epochs\")\n",
    "print(f\"   Retrained:     {len(history_v2.history['loss'])} epochs\")\n",
    "print(f\"\\n   The retrained model should train significantly longer!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b51a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final confusion matrix (retrained model)\n",
    "cm_v2 = confusion_matrix(y_test_balanced, y_pred_v2_classes)\n",
    "cm_v2_normalized = cm_v2.astype('float') / cm_v2.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "# First attempt\n",
    "cm_first = confusion_matrix(y_test_balanced, y_pred_balanced_classes)\n",
    "cm_first_normalized = cm_first.astype('float') / cm_first.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "sns.heatmap(cm_first_normalized, annot=True, fmt='.2f', cmap='Reds',\n",
    "            xticklabels=GESTURES, yticklabels=GESTURES, ax=ax1)\n",
    "ax1.set_xlabel('Predicted')\n",
    "ax1.set_ylabel('True')\n",
    "ax1.set_title('First Attempt (30% Accuracy - Stopped at Epoch 6)')\n",
    "\n",
    "# Retrained\n",
    "sns.heatmap(cm_v2_normalized, annot=True, fmt='.2f', cmap='Greens',\n",
    "            xticklabels=GESTURES, yticklabels=GESTURES, ax=ax2)\n",
    "ax2.set_xlabel('Predicted')\n",
    "ax2.set_ylabel('True')\n",
    "ax2.set_title('Retrained Model (Balanced Validation)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Look for:\")\n",
    "print(\"   - Stronger diagonal (correct predictions)\")\n",
    "print(\"   - More balanced predictions across all classes\")\n",
    "print(\"   - Reduced confusion between similar gestures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f97707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=GESTURES, yticklabels=GESTURES)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix (Normalized)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b478209",
   "metadata": {},
   "source": [
    "## 8. Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to Google Drive\n",
    "model_save_path = '/content/drive/MyDrive/silksong_data/cnn_lstm_gesture.h5'\n",
    "model.save(model_save_path)\n",
    "\n",
    "print(f\"✅ Model saved to: {model_save_path}\")\n",
    "print(\"\\nDownload this file to your local project and place it in the 'models/' directory\")\n",
    "print(\"Then run: python src/udp_listener_v3.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e889e1",
   "metadata": {},
   "source": [
    "## ✅ Training Complete!\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Download the trained model:**\n",
    "   - Right-click on the file in Google Drive: `silksong_data/cnn_lstm_gesture.h5`\n",
    "   - Download to your local machine\n",
    "\n",
    "2. **Place model in your project:**\n",
    "   ```bash\n",
    "   # Move to your project's models directory\n",
    "   mv ~/Downloads/cnn_lstm_gesture.h5 /path/to/project/models/\n",
    "   ```\n",
    "\n",
    "3. **Test real-time recognition:**\n",
    "   ```bash\n",
    "   cd src\n",
    "   python udp_listener_v3.py\n",
    "   ```\n",
    "\n",
    "4. **Expected performance:**\n",
    "   - Latency: 10-30ms per prediction\n",
    "   - Accuracy: 90-98%\n",
    "   - Much faster than Phase IV SVM model!\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or issues?** Check the documentation in `docs/Phase_V/README.md`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
