# Critical Data Preprocessing Fix: Sensor Row Merging

## Problem Identified

The original training data had **separate rows for each sensor type** with zeros in non-active sensor columns. This created a **zero-inflated dataset** that biased the machine learning models.

### Example of Original Data (FLAWED):
```csv
accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z,rot_w,rot_x,rot_y,rot_z,sensor,timestamp
0.0,0.0,0.0,0.0,0.0,0.0,0.928,-0.118,-0.093,0.340,rotation_vector,244452317059263
-6.486,-0.027,-5.809,0.0,0.0,0.0,1.0,0.0,0.0,0.0,linear_acceleration,244452356953341
0.0,0.0,0.0,-2.596,0.664,-3.595,1.0,0.0,0.0,0.0,gyroscope,244452356953341
```

**Issues:**
1. ‚ùå **Each row has 70% zeros** (only one sensor active)
2. ‚ùå **Temporal alignment lost** (same timestamp split across rows)
3. ‚ùå **Feature extraction biased** (statistics calculated over zero-inflated data)
4. ‚ùå **Model learns from incomplete patterns** (never sees full sensor fusion)

### Example of Fixed Data (MERGED):
```csv
accel_x,accel_y,accel_z,gyro_x,gyro_y,gyro_z,rot_w,rot_x,rot_y,rot_z,timestamp
-6.486,-0.027,-5.809,-2.596,0.664,-3.595,0.945,-0.165,-0.106,0.262,244452356953341
```

**Benefits:**
1. ‚úÖ **Complete sensor fusion per row** (all 10 IMU channels)
2. ‚úÖ **Temporal alignment preserved** (single timestamp per state)
3. ‚úÖ **Feature extraction accurate** (statistics from actual sensor values)
4. ‚úÖ **66% reduction in rows** (from 138 ‚Üí 46 rows for typical gesture)

---

## Solution Implemented

### Script: `src/shared_utils/merge_sensor_rows.py`

**Algorithm:**
1. Group rows by timestamp
2. For each timestamp:
   - Extract `accel_x/y/z` from `linear_acceleration` rows
   - Extract `gyro_x/y/z` from `gyroscope` rows
   - Extract `rot_w/x/y/z` from `rotation_vector` rows
3. Combine into single row with all sensor readings
4. Remove `sensor` column (no longer needed)

**Results:**
```
‚úÖ Successfully processed 408/408 files
üìä Average compression: 55% (138 rows ‚Üí 62 rows typical)
üìÇ Output: data/merged_training/
```

---

## Usage

### Process All Training Data
```bash
.venv/bin/python src/shared_utils/merge_sensor_rows.py \
    --input data/organized_training \
    --output data/merged_training
```

### Process Single Gesture Folder
```bash
.venv/bin/python src/shared_utils/merge_sensor_rows.py \
    --input data/organized_training/multiclass_classification/punch \
    --output data/test_merged_punch \
    --single-folder
```

### Process Raw Collected Data
```bash
.venv/bin/python src/shared_utils/merge_sensor_rows.py \
    --input data/button_collected \
    --output data/button_merged \
    --single-folder
```

---

## Impact on Training

### Before (Zero-Inflated Data)
```python
# Feature extraction gets:
accel_mean = [0, 0, 0, -6.5, 0, 0, -2.5, ...].mean()  # Diluted by zeros!
gyro_std = [0, 0, 0, 0, -2.6, 0, 0, ...].std()        # Inaccurate stats!
```

### After (Merged Data)
```python
# Feature extraction gets:
accel_mean = [-6.5, -6.8, -4.7, -6.1, ...].mean()     # Pure signal!
gyro_std = [-2.6, -2.8, -2.9, -2.4, ...].std()        # True variance!
```

### Expected Improvements
1. **Higher accuracy** - Model sees complete sensor patterns
2. **Better generalization** - Features based on real physics, not artifact zeros
3. **Balanced learning** - No bias toward "zero" predictions
4. **Faster convergence** - Cleaner signal-to-noise ratio

---

## Dataset Structure (After Merging)

```
data/merged_training/
‚îú‚îÄ‚îÄ binary_classification/
‚îÇ   ‚îú‚îÄ‚îÄ idle/         (30 samples, 5s each, ~100-200 merged rows per sample)
‚îÇ   ‚îú‚îÄ‚îÄ walk/         (30 samples, 5s each, ~100-200 merged rows per sample)
‚îÇ   ‚îî‚îÄ‚îÄ noise/        (baseline + noise segments)
‚îÇ
‚îî‚îÄ‚îÄ multiclass_classification/
    ‚îú‚îÄ‚îÄ jump/         (30 samples, 1-2s each, ~40-80 merged rows per sample)
    ‚îú‚îÄ‚îÄ punch/        (30 samples, 1-2s each, ~40-80 merged rows per sample)
    ‚îú‚îÄ‚îÄ turn_left/    (30 samples, 1-2s each, ~40-80 merged rows per sample)
    ‚îú‚îÄ‚îÄ turn_right/   (30 samples, 1-2s each, ~40-80 merged rows per sample)
    ‚îî‚îÄ‚îÄ noise/        (baseline + action noise segments)
```

**Sample Distribution:**
- Binary: 60 gesture samples (30 idle + 30 walk)
- Multiclass: 120 action samples (30 √ó 4 gestures)
- Total: 180 gesture samples + noise segments

---

## Next Steps

### 1. Retrain SVM Models
```bash
# Update training notebook to use merged data
# Edit: notebooks/SVM_Local_Training.py
DATA_DIR = PROJECT_ROOT / "data" / "merged_training"
```

### 2. Retrain CNN/LSTM Models
```bash
# Update Colab notebook data paths
# Upload merged_training/ to Google Drive
# Update: notebooks/watson_Colab_CNN_LSTM_Training.ipynb
```

### 3. Verify Feature Extraction Compatibility
```bash
# The feature_extractor.py already handles merged data correctly
# because it filters by sensor type during extraction
# No changes needed to feature extraction code!
```

### 4. Update Controllers
```bash
# Controllers use feature extraction which works with both formats
# May see improved accuracy with merged-trained models
# No code changes needed - just load new models
```

---

## Technical Details

### Merge Strategy Per Sensor

**Linear Acceleration:**
- Source: Rows where `sensor == 'linear_acceleration'`
- Columns: `accel_x`, `accel_y`, `accel_z`
- Default: `0.0` (if no reading at timestamp)

**Gyroscope:**
- Source: Rows where `sensor == 'gyroscope'`
- Columns: `gyro_x`, `gyro_y`, `gyro_z`
- Default: `0.0` (if no reading at timestamp)

**Rotation Vector:**
- Source: Rows where `sensor == 'rotation_vector'`
- Columns: `rot_w`, `rot_x`, `rot_y`, `rot_z`
- Default: `rot_w=1.0`, others `0.0` (identity quaternion)

### Timestamp Handling
- Sensors at Android level arrive at slightly different rates (~50Hz each)
- Merging by timestamp creates **one row per unique timestamp**
- Missing sensors at a timestamp get default values (rare - usually all 3 present)
- Result: ~50Hz merged stream with complete sensor state per row

---

## Validation

### Quick Check - Row Count Reduction
```bash
# Original punch sample: 138 rows
wc -l data/organized_training/multiclass_classification/punch/punch_1760841447588_to_1760841449332.csv
# Output: 138

# Merged punch sample: 46 rows (66% compression)
wc -l data/merged_training/multiclass_classification/punch/punch_1760841447588_to_1760841449332.csv
# Output: 47 (46 data + 1 header)
```

### Data Integrity Check
```bash
# Inspect merged data
head data/merged_training/multiclass_classification/punch/punch_*.csv

# Should show:
# - All 10 sensor columns filled (no systematic zeros)
# - Monotonic timestamps
# - Realistic IMU values
```

---

## Credits

**Issue Identified By:** User observation - "why are there so many zeros? shouldn't sensors be merged?"

**Root Cause:** Android Wear OS sends separate UDP packets per sensor type (standard design)

**Fix:** Created `merge_sensor_rows.py` to group by timestamp before training

**Date:** October 19, 2025

---

## References

- Original data: `data/organized_training/`
- Merged data: `data/merged_training/`
- Merge script: `src/shared_utils/merge_sensor_rows.py`
- Training notebooks:
  - `notebooks/SVM_Local_Training.py` (local SVM)
  - `notebooks/watson_Colab_CNN_LSTM_Training.ipynb` (Colab CNN/LSTM)
