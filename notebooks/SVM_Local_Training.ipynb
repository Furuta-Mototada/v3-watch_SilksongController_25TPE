{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f779936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SVM Local Training Notebook\n",
    "Optimized for local training on your machine (no Colab required)\n",
    "\n",
    "Two-Stage Classification:\n",
    "1. Binary: Walking vs Not-Walking\n",
    "2. Multi-class: Jump, Punch, Turn, Idle\n",
    "\n",
    "Usage:\n",
    "    1. Organize your data first: python src/organize_training_data.py\n",
    "    2. Run this notebook in Jupyter or VS Code\n",
    "    3. Or run as script: python notebooks/SVM_Local_Training.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2676bcbc",
   "metadata": {},
   "source": [
    "# SVM Local Training - Silksong Gesture Recognition\n",
    "\n",
    "**Fast Local Training with Support Vector Machines**\n",
    "\n",
    "This notebook trains SVM models for gesture recognition on your local machine.\n",
    "No GPU required, training takes 5-15 minutes.\n",
    "\n",
    "## Setup Requirements:\n",
    "1. ‚úÖ Organized data in `data/organized_training/`\n",
    "2. ‚úÖ Python packages: scikit-learn, pandas, numpy, joblib\n",
    "\n",
    "## Two-Stage Architecture:\n",
    "- **Stage 1**: Binary classifier (Walking vs Not-Walking)\n",
    "- **Stage 2**: Multi-class classifier (Jump, Punch, Turn, Idle)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db4897e",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dba384",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from scipy.fft import fft\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Paths (adjust if needed)\n",
    "PROJECT_ROOT = Path(__file__).parent.parent if __file__ else Path.cwd().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"organized_training\"\n",
    "MODEL_OUTPUT_DIR = PROJECT_ROOT / \"models\"\n",
    "MODEL_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Training mode: 'BINARY', 'MULTICLASS', or 'BOTH'\n",
    "TRAINING_MODE = 'BOTH'  # Train both classifiers\n",
    "\n",
    "print(f\"üìÇ Project root: {PROJECT_ROOT}\")\n",
    "print(f\"üìÇ Data directory: {DATA_DIR}\")\n",
    "print(f\"üìÇ Model output: {MODEL_OUTPUT_DIR}\")\n",
    "print(f\"üéØ Training mode: {TRAINING_MODE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af2210",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4cf5b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_gesture_data(data_path, gestures):\n",
    "    \"\"\"\n",
    "    Load all CSV files for each gesture class.\n",
    "    \n",
    "    Returns:\n",
    "        List of (DataFrame, label, label_idx) tuples\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for gesture_idx, gesture in enumerate(gestures):\n",
    "        gesture_path = data_path / gesture\n",
    "        \n",
    "        if not gesture_path.exists():\n",
    "            print(f\"‚ö†Ô∏è  Warning: {gesture} folder not found at {gesture_path}\")\n",
    "            continue\n",
    "        \n",
    "        csv_files = list(gesture_path.glob(\"*.csv\"))\n",
    "        \n",
    "        for csv_file in csv_files:\n",
    "            try:\n",
    "                df = pd.read_csv(csv_file)\n",
    "                all_data.append((df, gesture, gesture_idx))\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading {csv_file.name}: {e}\")\n",
    "        \n",
    "        print(f\"‚úÖ Loaded {len(csv_files)} samples for '{gesture}'\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def check_metadata(data_dir):\n",
    "    \"\"\"Load and display metadata about organized data.\"\"\"\n",
    "    metadata_path = data_dir / \"metadata.json\"\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path) as f:\n",
    "            metadata = json.load(f)\n",
    "        print(\"\\nüìä Data Organization:\")\n",
    "        print(f\"  Total files: {metadata.get('total_files_organized', 'N/A')}\")\n",
    "        print(f\"  Binary: {metadata.get('binary_classification', {})}\")\n",
    "        print(f\"  Multi-class: {metadata.get('multiclass_classification', {})}\")\n",
    "        print(f\"  Noise: {metadata.get('noise_detection', {})}\")\n",
    "        return metadata\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No metadata.json found\")\n",
    "        return None\n",
    "\n",
    "# Check metadata\n",
    "metadata = check_metadata(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f9e99",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_dataframe(df):\n",
    "    \"\"\"\n",
    "    Extract comprehensive features from sensor data.\n",
    "    \n",
    "    Features:\n",
    "    - Time domain: mean, std, min, max, range, median, skew, kurtosis\n",
    "    - Frequency domain: FFT max, dominant frequency\n",
    "    - Magnitude features: accel magnitude, gyro magnitude\n",
    "    \n",
    "    Returns:\n",
    "        dict of features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Separate by sensor type\n",
    "    accel_data = df[df['sensor'] == 'linear_acceleration']\n",
    "    gyro_data = df[df['sensor'] == 'gyroscope']\n",
    "    rot_data = df[df['sensor'] == 'rotation_vector']\n",
    "    \n",
    "    def time_features(series, prefix):\n",
    "        \"\"\"Extract time-domain features.\"\"\"\n",
    "        if len(series) == 0:\n",
    "            return {}\n",
    "        return {\n",
    "            f'{prefix}_mean': np.mean(series),\n",
    "            f'{prefix}_std': np.std(series),\n",
    "            f'{prefix}_min': np.min(series),\n",
    "            f'{prefix}_max': np.max(series),\n",
    "            f'{prefix}_range': np.max(series) - np.min(series),\n",
    "            f'{prefix}_median': np.median(series),\n",
    "            f'{prefix}_skew': stats.skew(series),\n",
    "            f'{prefix}_kurtosis': stats.kurtosis(series),\n",
    "        }\n",
    "    \n",
    "    def freq_features(series, prefix):\n",
    "        \"\"\"Extract frequency-domain features.\"\"\"\n",
    "        if len(series) < 4:\n",
    "            return {f'{prefix}_fft_max': 0, f'{prefix}_dom_freq': 0}\n",
    "        \n",
    "        fft_vals = np.abs(fft(series))\n",
    "        return {\n",
    "            f'{prefix}_fft_max': np.max(fft_vals[:len(fft_vals)//2]),\n",
    "            f'{prefix}_dom_freq': np.argmax(fft_vals[:len(fft_vals)//2])\n",
    "        }\n",
    "    \n",
    "    # Accelerometer features\n",
    "    for axis in ['x', 'y', 'z']:\n",
    "        col = f'accel_{axis}'\n",
    "        if col in accel_data.columns and len(accel_data) > 0:\n",
    "            series = accel_data[col].dropna()\n",
    "            features.update(time_features(series, f'accel_{axis}'))\n",
    "            features.update(freq_features(series, f'accel_{axis}'))\n",
    "    \n",
    "    # Gyroscope features\n",
    "    for axis in ['x', 'y', 'z']:\n",
    "        col = f'gyro_{axis}'\n",
    "        if col in gyro_data.columns and len(gyro_data) > 0:\n",
    "            series = gyro_data[col].dropna()\n",
    "            features.update(time_features(series, f'gyro_{axis}'))\n",
    "            features.update(freq_features(series, f'gyro_{axis}'))\n",
    "    \n",
    "    # Rotation features (quaternion)\n",
    "    for axis in ['w', 'x', 'y', 'z']:\n",
    "        col = f'rot_{axis}'\n",
    "        if col in rot_data.columns and len(rot_data) > 0:\n",
    "            series = rot_data[col].dropna()\n",
    "            features.update(time_features(series, f'rot_{axis}'))\n",
    "    \n",
    "    # Magnitude features\n",
    "    if len(accel_data) > 0 and all(f'accel_{ax}' in accel_data.columns for ax in ['x', 'y', 'z']):\n",
    "        accel_mag = np.sqrt(\n",
    "            accel_data['accel_x']**2 + \n",
    "            accel_data['accel_y']**2 + \n",
    "            accel_data['accel_z']**2\n",
    "        )\n",
    "        features.update(time_features(accel_mag, 'accel_mag'))\n",
    "    \n",
    "    if len(gyro_data) > 0 and all(f'gyro_{ax}' in gyro_data.columns for ax in ['x', 'y', 'z']):\n",
    "        gyro_mag = np.sqrt(\n",
    "            gyro_data['gyro_x']**2 + \n",
    "            gyro_data['gyro_y']**2 + \n",
    "            gyro_data['gyro_z']**2\n",
    "        )\n",
    "        features.update(time_features(gyro_mag, 'gyro_mag'))\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"‚úÖ Feature extraction function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b780267",
   "metadata": {},
   "source": [
    "## 4. Train Binary Classifier (Walking vs Not-Walking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a1dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING_MODE in ['BINARY', 'BOTH']:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STAGE 1: BINARY CLASSIFIER (Walking vs Not-Walking)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Load binary data\n",
    "    binary_path = DATA_DIR / \"binary_classification\"\n",
    "    binary_gestures = ['walking', 'not_walking']\n",
    "    \n",
    "    print(\"Loading binary classification data...\")\n",
    "    binary_data = load_gesture_data(binary_path, binary_gestures)\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"\\nExtracting features...\")\n",
    "    X_binary_features = []\n",
    "    y_binary_labels = []\n",
    "    \n",
    "    for i, (df, gesture, gesture_idx) in enumerate(binary_data):\n",
    "        try:\n",
    "            features = extract_features_from_dataframe(df)\n",
    "            X_binary_features.append(features)\n",
    "            y_binary_labels.append(gesture_idx)\n",
    "            \n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f\"  Processed {i + 1}/{len(binary_data)} samples...\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    # Convert to arrays\n",
    "    X_binary_df = pd.DataFrame(X_binary_features).fillna(0)\n",
    "    y_binary = np.array(y_binary_labels)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Feature extraction complete!\")\n",
    "    print(f\"   Shape: {X_binary_df.shape}\")\n",
    "    print(f\"   Features: {len(X_binary_df.columns)}\")\n",
    "    \n",
    "    # Check class distribution\n",
    "    unique, counts = np.unique(y_binary, return_counts=True)\n",
    "    print(f\"\\nüìä Class distribution:\")\n",
    "    for label, count in zip(binary_gestures, counts):\n",
    "        print(f\"   {label}: {count} samples\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(\n",
    "        X_binary_df, y_binary,\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_SEED,\n",
    "        stratify=y_binary\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_binary = StandardScaler()\n",
    "    X_train_b_scaled = scaler_binary.fit_transform(X_train_b)\n",
    "    X_test_b_scaled = scaler_binary.transform(X_test_b)\n",
    "    \n",
    "    print(f\"\\nTrain set: {X_train_b.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test_b.shape[0]} samples\")\n",
    "    \n",
    "    # Train SVM\n",
    "    print(\"\\nTraining SVM (this may take 2-5 minutes)...\")\n",
    "    svm_binary = SVC(\n",
    "        kernel='rbf',\n",
    "        C=1.0,\n",
    "        gamma='scale',\n",
    "        random_state=RANDOM_SEED,\n",
    "        probability=True\n",
    "    )\n",
    "    svm_binary.fit(X_train_b_scaled, y_train_b)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_acc_b = svm_binary.score(X_train_b_scaled, y_train_b)\n",
    "    test_acc_b = svm_binary.score(X_test_b_scaled, y_test_b)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Binary SVM training complete!\")\n",
    "    print(f\"   Training accuracy: {train_acc_b:.2%}\")\n",
    "    print(f\"   Test accuracy: {test_acc_b:.2%}\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_b = svm_binary.predict(X_test_b_scaled)\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_b, y_pred_b, target_names=binary_gestures))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm_b = confusion_matrix(y_test_b, y_pred_b)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm_b, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=binary_gestures, yticklabels=binary_gestures)\n",
    "    plt.title('Binary Classifier: Walking vs Not-Walking')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(MODEL_OUTPUT_DIR / 'binary_confusion_matrix.png', dpi=300)\n",
    "    print(f\"\\nüíæ Confusion matrix saved to: {MODEL_OUTPUT_DIR / 'binary_confusion_matrix.png'}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Save model\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    joblib.dump(svm_binary, MODEL_OUTPUT_DIR / f\"gesture_classifier_binary_{timestamp}.pkl\")\n",
    "    joblib.dump(scaler_binary, MODEL_OUTPUT_DIR / f\"feature_scaler_binary_{timestamp}.pkl\")\n",
    "    joblib.dump(list(X_binary_df.columns), MODEL_OUTPUT_DIR / f\"feature_names_binary_{timestamp}.pkl\")\n",
    "    \n",
    "    # Also save as default names (for easy loading)\n",
    "    joblib.dump(svm_binary, MODEL_OUTPUT_DIR / \"gesture_classifier_binary.pkl\")\n",
    "    joblib.dump(scaler_binary, MODEL_OUTPUT_DIR / \"feature_scaler_binary.pkl\")\n",
    "    joblib.dump(list(X_binary_df.columns), MODEL_OUTPUT_DIR / \"feature_names_binary.pkl\")\n",
    "    \n",
    "    print(f\"\\nüíæ Binary model saved to: {MODEL_OUTPUT_DIR}/\")\n",
    "    print(f\"   - gesture_classifier_binary.pkl\")\n",
    "    print(f\"   - feature_scaler_binary.pkl\")\n",
    "    print(f\"   - feature_names_binary.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef04b7c",
   "metadata": {},
   "source": [
    "## 5. Train Multi-class Classifier (Jump, Punch, Turn, Idle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING_MODE in ['MULTICLASS', 'BOTH']:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STAGE 2: MULTI-CLASS CLASSIFIER (Jump, Punch, Turn, Idle)\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Load multiclass data\n",
    "    multiclass_path = DATA_DIR / \"multiclass_classification\"\n",
    "    multiclass_gestures = ['jump', 'punch', 'turn', 'idle']\n",
    "    \n",
    "    print(\"Loading multi-class data...\")\n",
    "    multiclass_data = load_gesture_data(multiclass_path, multiclass_gestures)\n",
    "    \n",
    "    # Extract features\n",
    "    print(\"\\nExtracting features...\")\n",
    "    X_multi_features = []\n",
    "    y_multi_labels = []\n",
    "    \n",
    "    for i, (df, gesture, gesture_idx) in enumerate(multiclass_data):\n",
    "        try:\n",
    "            features = extract_features_from_dataframe(df)\n",
    "            X_multi_features.append(features)\n",
    "            y_multi_labels.append(gesture_idx)\n",
    "            \n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f\"  Processed {i + 1}/{len(multiclass_data)} samples...\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    # Convert to arrays\n",
    "    X_multi_df = pd.DataFrame(X_multi_features).fillna(0)\n",
    "    y_multi = np.array(y_multi_labels)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Feature extraction complete!\")\n",
    "    print(f\"   Shape: {X_multi_df.shape}\")\n",
    "    print(f\"   Features: {len(X_multi_df.columns)}\")\n",
    "    \n",
    "    # Check class distribution\n",
    "    unique, counts = np.unique(y_multi, return_counts=True)\n",
    "    print(f\"\\nüìä Class distribution:\")\n",
    "    for label, count in zip(multiclass_gestures, counts):\n",
    "        print(f\"   {label}: {count} samples\")\n",
    "    \n",
    "    # Warn about imbalance\n",
    "    max_count = max(counts)\n",
    "    min_count = min(counts)\n",
    "    if max_count > min_count * 1.3:\n",
    "        print(f\"\\n‚ö†Ô∏è  Warning: Class imbalance (ratio: {max_count/min_count:.2f}x)\")\n",
    "        print(f\"   Consider collecting more data for minority classes\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
    "        X_multi_df, y_multi,\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_SEED,\n",
    "        stratify=y_multi\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler_multi = StandardScaler()\n",
    "    X_train_m_scaled = scaler_multi.fit_transform(X_train_m)\n",
    "    X_test_m_scaled = scaler_multi.transform(X_test_m)\n",
    "    \n",
    "    print(f\"\\nTrain set: {X_train_m.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test_m.shape[0]} samples\")\n",
    "    \n",
    "    # Train SVM\n",
    "    print(\"\\nTraining SVM (this may take 2-5 minutes)...\")\n",
    "    svm_multi = SVC(\n",
    "        kernel='rbf',\n",
    "        C=1.0,\n",
    "        gamma='scale',\n",
    "        random_state=RANDOM_SEED,\n",
    "        probability=True\n",
    "    )\n",
    "    svm_multi.fit(X_train_m_scaled, y_train_m)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_acc_m = svm_multi.score(X_train_m_scaled, y_train_m)\n",
    "    test_acc_m = svm_multi.score(X_test_m_scaled, y_test_m)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Multi-class SVM training complete!\")\n",
    "    print(f\"   Training accuracy: {train_acc_m:.2%}\")\n",
    "    print(f\"   Test accuracy: {test_acc_m:.2%}\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_m = svm_multi.predict(X_test_m_scaled)\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_m, y_pred_m, target_names=multiclass_gestures))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm_m = confusion_matrix(y_test_m, y_pred_m)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm_m, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=multiclass_gestures, yticklabels=multiclass_gestures)\n",
    "    plt.title('Multi-class Classifier: Jump, Punch, Turn, Idle')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(MODEL_OUTPUT_DIR / 'multiclass_confusion_matrix.png', dpi=300)\n",
    "    print(f\"\\nüíæ Confusion matrix saved to: {MODEL_OUTPUT_DIR / 'multiclass_confusion_matrix.png'}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Save model\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    joblib.dump(svm_multi, MODEL_OUTPUT_DIR / f\"gesture_classifier_multiclass_{timestamp}.pkl\")\n",
    "    joblib.dump(scaler_multi, MODEL_OUTPUT_DIR / f\"feature_scaler_multiclass_{timestamp}.pkl\")\n",
    "    joblib.dump(list(X_multi_df.columns), MODEL_OUTPUT_DIR / f\"feature_names_multiclass_{timestamp}.pkl\")\n",
    "    \n",
    "    # Also save as default names\n",
    "    joblib.dump(svm_multi, MODEL_OUTPUT_DIR / \"gesture_classifier_multiclass.pkl\")\n",
    "    joblib.dump(scaler_multi, MODEL_OUTPUT_DIR / \"feature_scaler_multiclass.pkl\")\n",
    "    joblib.dump(list(X_multi_df.columns), MODEL_OUTPUT_DIR / \"feature_names_multiclass.pkl\")\n",
    "    \n",
    "    print(f\"\\nüíæ Multi-class model saved to: {MODEL_OUTPUT_DIR}/\")\n",
    "    print(f\"   - gesture_classifier_multiclass.pkl\")\n",
    "    print(f\"   - feature_scaler_multiclass.pkl\")\n",
    "    print(f\"   - feature_names_multiclass.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05694ee5",
   "metadata": {},
   "source": [
    "## 6. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0b18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if TRAINING_MODE in ['BINARY', 'BOTH']:\n",
    "    print(f\"\\nüìä Binary Classifier (Walking vs Not-Walking):\")\n",
    "    print(f\"   Test Accuracy: {test_acc_b:.2%}\")\n",
    "    print(f\"   Model: models/gesture_classifier_binary.pkl\")\n",
    "\n",
    "if TRAINING_MODE in ['MULTICLASS', 'BOTH']:\n",
    "    print(f\"\\nüìä Multi-class Classifier (Jump, Punch, Turn, Idle):\")\n",
    "    print(f\"   Test Accuracy: {test_acc_m:.2%}\")\n",
    "    print(f\"   Model: models/gesture_classifier_multiclass.pkl\")\n",
    "\n",
    "print(f\"\\n‚ú® Next Steps:\")\n",
    "print(f\"   1. Test models with: python src/udp_listener.py\")\n",
    "print(f\"   2. Models are in: {MODEL_OUTPUT_DIR}/\")\n",
    "print(f\"   3. Update controller to use two-stage classification\")\n",
    "\n",
    "print(f\"\\nüí° Two-Stage Controller Logic:\")\n",
    "print(f\"   Step 1: Run binary classifier\")\n",
    "print(f\"   Step 2: If 'not_walking', run multi-class classifier\")\n",
    "print(f\"   Step 3: Execute action based on prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5bf183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python3",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
